\paragraph{}O objetivo deste capitulo é trazer a fundamentação teórica das técnicas utilizadas neste trabalho. Em primeiro lugar será abordada a teoria, aplicações e dificuldades relacionadas às séries temporais. Logo após, serão apresentados os modelos de aprendizados de máquina utilizados como redes neurais MLP.

\section{Séries Temporais} \label{series_temporais}
\paragraph{}Uma série temporal é composta por uma coleção de observações feitas de forma sequencial e dependente \cite{sTemp}. Essa ordem da sequência é dada pelo tempo, o qual pode ser contínuo ou discreto. No primeiro caso, $T = {t : t_1 < t < t_2}$ e a série temporal é definida como $\{X(t) : t \in T\}$, já no segundo caso, $T = \{t_1, t_2, ... , t_n\}$ e a série temporal é definida como $\{X_t : t \in T\}$, onde X é a variável observada. Geralmente define-se o T para o caso discreto como $T = \{1, 2, ..., n\}$ por questões de simplicidade. Neste trabalho será utilizado o caso discreto, dado que a amostragem do sinal tem periodicidade mensal. Sendo assim, os exemplos dados no trabalho serão discretos também.

\paragraph{}Assim como o tempo, os valores da variável $X_t$ podem ser contínuos ou discretos de acordo com o fenômeno que se observa. Alguns exemplos de fenômenos temporais com valores contínuos são a temperatura em um determinada região, volume de água em uma bacia hidrográfica e o peso de um indivíduo. Já como exemplo de fenômenos temporais com valores discretos podem ser citados o número  viagens de avião, quantidade de nascimentos, de carros produzidos por uma montadora etc. Todos esse casos estão relacionados com um período de observação próprio, podendo ser uma janela de meses, anos, até mesmo décadas de observações de uma determinada variável.

\paragraph{}A análise de séries temporais pode ser feita com diferentes intuitos, sendo os mais comuns a predição de valores futuros com base no histórico já conhecido, o controle de um processo, a explicação e descrição de fenômenos \cite{sTemp}.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{exemplo_tsa.jpg}
				
				\caption[\small{Exemplo de decomposição de série temporal \cite{shampooSales} }]{\label{exemploTSA} \small{Exemplo de decomposição de série temporal. Fonte:	Makridakis, Wheelwright and Hyndman (1998) \cite{shampooSales}}}
				
			\end{center}
			
		}
		
	\end{center}
	
\end{figure}

\paragraph{}Buscando tornar a análise das séries temporais mais simples, além de facilitar a extração de informações importantes de maneira gráfica, é comum decompor a série em outras mais simples. A decomposição utilizada será a seguinte, conforme visto em \cite{apostilaCaloba}:

\begin{equation*}
	X_t = tend_t + sz_t + cs_t + res_t
\end{equation*}

\paragraph{}Onde $tend_t$ é a tendência, $sz_t$ é a sazonalidade, $cs_t$ é o ciclo senoidal e $res_t$ é o resíduo. Tanto a tendência, quanto a sazonalidade e os ciclos senoidais são determinísticos. Conforme \cite{tccDanilo}, boa parte das séries temporais são não estacionárias, sendo que as componentes de tendência e sazonalidade são as maiores responsáveis por esse efeito. Para que o modelo com redes neurais faça boas previsões, que é o que se busca nesse trabalho, é necessário utilizar séries estacionárias, portanto somente a parte residual será usada na entrada das redes neurais.

\subsection{Tendência}
\paragraph{}Segundo \cite{sTemp}, a tendência pode ser vista como "uma mudança de longo prazo no nível médio da série" e a forma mais simples de modelar pode ser vista pela equação a seguir. 

\begin{equation}
tend_t = \alpha + \beta t + \epsilon_t
\end{equation}

\paragraph{}Onde $\alpha$ e $\beta$ são constantes a serem estimadas e $\epsilon_t$ denota um erro aleatório com média zero. Geralmente chama-se o termo $m_t = \alpha + \beta t$ de termo de tendência, mas alguns autores chamam o termo $\beta$ de tendência, já que $\beta = m_t - m_{t-1}$. Essa variável indica a inclinação da função durante o tempo.

\paragraph{}A função utilizada na aproximação da tendência pode ser escolhida de acordo com a série que está sendo analisada. Uma forma bastante comum é a utilização de uma função polinomial na extração de tendência.

\paragraph{}Na tendência polinomial \ref{eqTendPoli}, busca-se fazer uma extração boa o suficiente para obter-se ao final do processamento a componente residual estacionária com média zero. Para séries monotonicamente crescente ou decrescente, utilizar $p = 1$ (função linear)  ou $p = 2$ (função quadrática) geralmente é suficiente para a extração da tendência, porém caso a série seja mais complexa, pode ser necessário utilizar funções de ordem mais altas

\begin{equation} \label{eqTendPoli}
tend_t = \epsilon_t + \sum_{n=0}^{p} \beta_n t^n
\end{equation}

\paragraph{}Alguns métodos de filtragem podem ser utilizados também na extração de tendência. É comum utilizar filtros lineares nessa tarefa. Esses são definidos pela seguinte equação:

\begin{equation}
y_t = \sum_{j = -q}^{s} a_jx_{t+j}
\end{equation}

\paragraph{}Onde $a_j$ são os pesos que multiplicam o sinal $x_{t+j}$. Para o filtro de médias móveis geralmente utiliza-se $q=s$ e $a_{-r} = a_r$, garantindo a simetria do filtro. Além disso faz-se que $\sum_{j = -q}^{s} a_j = 1$, de modo que $min\{x_t\} \leq y_t \leq max\{x_t\}$. O caso mais simples de média móvel é aquele onde todos os pesos tem o mesmo valor:

\begin{equation}
y_t = \dfrac{1}{2q + 1} \sum_{j = -q}^{q} x_{t + j}
\end{equation}

\paragraph{}O resultado do filtro acima é não-causal, o que impede que o processamento seja utilizado para a previsão de séries. Sendo assim, uma outra abordagem possível é fazer um deslocamento no filtro para que sejam utilizadas somente amostras do passado, conforme a equação a seguir:

\begin{equation}\label{mediaMovelSimples}
	y_t =  \dfrac{1}{2q + 1} \sum_{j = -2q}^{0} x_{t+j}
\end{equation} 

\paragraph{}Outro problema observado nas abordagens de média móvel descritas acima é que somente é que só se obtém a tendência para $N - 2q$ pontos. Caso seja necessário obter a tendência para todos os pontos da série, pode-se aplicar métodos de extrapolação sobre o resultado obtido.

\paragraph{}Uma terceira abordagem para extração de tendência é utilizar um filtro com pesos que decaem geometricamente, com j, priorizando assim, as amostras mais recentes da série temporal:

\begin{equation}
y_t = \sum_{j=0}^{\infty} \alpha (1 - \alpha)^j x_{t-j}
\end{equation}

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{exemplo2_tendencia.jpg}
				
				\caption[\small{Exemplo de extração de tendência com filtro de média \cite{birthNY} }]{\label{bNYtend} \small{Exemplo de extração de tendência com filtro de média. Fonte: Newton (1998). \cite{birthNY}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}

\paragraph{}Outra forma de extrair a tendência é através da diferenciação. Para dados não sazonais, a primeira diferença costuma ser suficiente para garantir a estacionariedade aproximada da série  restante \cite{sTemp}:

\begin{equation}
y_t = x_t - x_{t-1} = \nabla x_t
\end{equation}


\subsection{Sazonalidade}
\paragraph{}É comum encontrar nas séries observadas alguns padrões que se repetem periodicamente. Esse efeito é denominado sazonalidade e deve ser removido para que se obtenha ao final do processamento uma série residual estacionária \cite{apostilaCaloba}.

\paragraph{}Segundo \cite{apostilaCaloba}, a sazonalidade pode ser determinada pela seguinte fórmula:

\begin{equation}
sz_t = \dfrac{1}{Int(N/P)} \sum_{k = 0}^{Int(N/P)} s_i (i + kP) \quad \quad i=1,...,P
\end{equation}

\paragraph{} Onde $N$ é o número de amostras, $P$ é o período sazonal, $Int(N/P)$ é o resultado inteiro da divisão de $N/P$ e $s_i$ é o sinal com a tendência previamente removida. Sendo assim, é feito uma média dos pontos da série temporal espaçados pelo período $P$. A sazonalidade se repete durante a série temporal, então, caso seja desejado obter a sazonalidade em um tempo $0 < t < N$ utiliza-se a seguinte fórmula:

\begin{equation}
sz_t = sz[Resto(t/P)]
\end{equation}

\paragraph{}A periodicidade do fenômeno sazonal pode ser obtida através do conhecimento prévio da série que está sendo analisada ex: Espera-se que a venda de protetores solares seja maior no período de verão, pois é quando as pessoas costumam ir mais às praias. O número de pessoas que frequentam o metrô deve diminuir durante o fim de semana, pois a maioria trabalha durante a semana etc.

\paragraph{}Outra forma de se obter o período é fazendo uma inspeção visual sobre o gráfico da série após a remoção da tendência. Em alguns casos serão visíveis os padrões periódicos.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{exemplo2_sazonalidade.jpg}
				
				\caption[\small{Extração de sazonalidade com periodicidade anual ($P=12$) para o dataset de nascimentos em Nova York\cite{birthNY} }]{\label{bNYsaz} \small{Extração de sazonalidade com periodicidade anual ($P=12$) para o dataset de nascimentos em Nova York. Fonte: Newton (1988). \cite{birthNY}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}


\paragraph{}Também pode-se obter a informação sobre o período através da observação do gráfico de autocorrelação, onde picos de magnitude seguindo um padrão de espaçamento podem indicar a periodicidade da sazonalidade.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{exemplo2_autocorrelacao.jpg}
				
				\caption[\small{Autocorrelação para o sinal residual do dataset de nascimentos em Nova York\cite{birthNY} }]{\label{bNYautocorr} \small{Autocorrelação para o sinal residual do dataset de nascimentos em Nova York. Fonte: Newton (1988). \cite{birthNY}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}


\subsection{Ciclos Senoidais}
\paragraph{} Os ciclos senoidais representam um caso bem específico de sazonalidade, sendo representados por senoides de período $P$. Essa senoide é extraída através da análise do espectrograma dado pela FFT-\textit{Fast Fourier Transform}. Os parâmetros de sáida são os termos a e b, conforme vistos nas equações abaixo\cite{introSP}:

\begin{equation}
cs_t = a \cdot \cos(2\pi f t) + b \cdot \sin(2 \pi f t)
\end{equation}

\paragraph{}Os pontos onde a magnitude do sinal ($\sqrt{a² + b²}$) são muito maiores que os outros indicam provável ciclos senoidais que devem ser removidos.

\subsection{Componente Residual} \label{Residuo}
\paragraph{}Caso o processo de extração de componentes descrito nos tópicos acima seja realizado com sucesso, será obtida uma componente residual estacionária. Busca-se também uma distribuição próxima da normal para facilitar a análise. Seguindo esta abordagem, este sinal residual é a única parte aleatória do modelo. Sendo assim, o problema se reduz a prever o comportamento da parte residual da série temporal.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{exemplo2_residual.jpg}
				
				\caption[\small{Residuo sem remoção de ciclos senoidasi para o dataset de nascimentos em Nova York\cite{birthNY} }]{\label{bNYres} \small{Resíduo sem remoção de ciclos senoidais para o dataset de nascimentos em Nova York. Fonte: Newton (1988). \cite{birthNY}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[scale=0.3]{exemplo2_residual_filtrado.jpg}
				
				\caption[\small{Residuo com remoção de ciclos senoidas para o dataset de nascimentos em Nova York. Filtro Notch com $\omega_0 = 0.135rad\\amostra$ e $Q=0.2$ \cite{birthNY} }]{\label{bNYresFilt} \small{Residuo com remoção de ciclos senoidais para o dataset de nascimentos em Nova York. Fonte: Newton (1988). \cite{birthNY}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}


\paragraph{}Como pode-se observar, o sinal residual após a remoção de ciclos senoidais diminuiu-se a discrepância gerada pelas frequências próximas de $\omega_0 = 0.135rad\\amostra$ além de deixar a distribuição menos espaçada (O desvio padrão mudou de aproximadamente $\sigma=0.37$ para $\sigma=0.14$).

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{exemplo2_residual_tempo.jpg}
				
				\caption[\small{Sinal residual no tempo para o dataset de nascimentos em Nova York \cite{birthNY} }]{\label{bNYresFiltTempo} \small{Sinal residual no tempo para o dataset de nascimentos em Nova York Fonte: Newton (1988). \cite{birthNY}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}


\section{Processamento de Sinais}
\paragraph{}Para remover os ciclos senoidais do espectrograma visto em \ref{bNYres} é necessário realizar algum tipo de filtragem sobre sinal. Uma das formas de se classificar um filtro é pela sua resposta em frequência, sendo as mais comuns: passa-baixa, passa-alta, passa-banda e rejeita-banda.

\paragraph{}No problema de remoção de ciclos senoidais, busca-se um filtro que remova somente a frequência com maior magnitude, sem afetar muito as magnitudes das outras frequências presentes no espectrograma. Para isso procura-se um filtro que seja rejeita-banda com a banda de rejeição bem estreita e banda de passagem aproximadamente plana.

\paragraph{}Um filtro bastante conhecido na literatura que atende a esse critério é o Notch. A escolha pela versão IIRs se dá pela possibilidade de obter atenuações maiores e banda de rejeição mais estreita para um mesma ordem $N$ quando comparado com os filtros FIRs. A função de transferência do filtro Notch de segunda ordem se dá pela equação a seguir: \cite{introSP}:

\begin{equation} \label{notch}
H(z) = b \cdot \frac{1 - 2\cos \omega_0 z^{-1} + z^{-2}}{1 - 2b\cos \omega_0 z^{-1} + (2b - 1) z^{-2}}
\end{equation}

e 

\begin{equation}
b = \frac{1}{ 1 + \beta} = \frac{1}{1 + \frac{\sqrt{1 - G_b²}}{G_b} \tan(\frac{\Delta \omega}{2})}
\end{equation}


\paragraph{}Onde $\omega_0$ é a frequência que se deseja rejeitar, $\Delta \omega$ é a banda de rejeição, $G_b$ é a atenuação na frequência de corte. Geralmente utiliza-se $G_b = 3dB$. O parâmetro $Q$ citado na seção \ref{Residuo} pode ser definido também como $Q = \frac{\omega_0}{bw}$. $bw$ por sua vez é a banda de rejeição do filtro Notch.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[scale=0.45]{notch.png}
				
				\caption[\small{Filtro Notch IIR digital\cite{introSP} }]{\label{Notch} \small{Filtro Notch IIR digital Fonte: Introduction to Signal Processing. \cite{introSP}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}

\section{Redes Neurais Artificiais}
\paragraph{}Redes Neurais artificiais são modelos computacionais que tentam reproduzir o comportamento observado na estrutura cerebral dos seres vivos. O neurônio pode ser considerado a célula básica de processamento do cérebro humano. Sua estrutura é divida em três partes principais \cite{apostilaCaloba}  \cite{ivan_nunes} \cite{Gurney}:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[height=0.25\textheight]{neuronio_biologico.jpg}
				
				\caption[\small{Neurônio \cite{neuronio} }]{\label{neuronio_biologico} \small{Neurônio. Fonte: \cite{neuronio}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}

\begin{itemize}
	\item {\textbf{Dendritos: } São responsáveis por receber estímulos elétricos de outros neurônios}
	\item {\textbf{Corpo celular: } Processa as informações recebidas pelos dendritos e determina se será disparado um impulso elétrico}
	\item {\textbf{Axônio: } Transmite o impulso elétrico, e, através das sinapses, envia a informação para outros neurônios. Isto ocorre sem contato entre os mesmos.}
\end{itemize}

\paragraph{}A representação matemática desse modelo é dada pela seguinte estrutura:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=0.8\textwidth]{neuronio_artificial.jpg}
				
				\caption[\small{Neurônio \cite{neuronio_artificial} }]{\label{neuronio_artificial} \small{Neurônio Artificial. Fonte: \cite{neuronio_artificial}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}


\paragraph{}A entrada do neurônio é um vetor $X = [x_1, x_2 ..., x_n]$
análogo ao sinais elétricos transmitidos no cérebro humano. Essa entrada é ponderada por um conjunto de pesos $W = [w_1, w_2, ..., w_N]$ e somada em um combinador linear junto com um limiar de ativação $\theta$. O somatório das entradas gera um potencial de ativação $u$, o qual passa por uma função de ativação e gera um sinal de saída que poderá ser propagado para outros neurônios \cite{ivan_nunes}. As informações descritas acima se resumem nas seguintes equações \cite{mlp_book}:

\begin{equation} \label{eq_neuronio}
 u_j = \sum_{i = 1}^{N} w_{ji} \cdot x_i - \theta
\end{equation}

\begin{equation}
y = g(u)
\end{equation}

\paragraph{}Sendo que se considerar $x_0 = 1$ e $w_0 = -\theta$, pode-se definir a equação \ref{eq_neuronio} como:

\begin{equation}
u = \sum_{i = 0}^{n} w_i \cdot x_i
\end{equation}

\paragraph{}A função de ativação pode ter diferentes formatos. Caso seja identidade, obtém se um regressor linear \cite{Bishop}. Este tipo de abordagem traz uma grande desvantagem, pois a saída do sistema sempre será linear. Isto vem do fato de que uma composição de transformações lineares é também uma transformação linear. Sendo assim, nas redes neurais são utilizadas funções não-lineares. Alguns exemplos são:
\begin{itemize}
	\item {\textbf{Função Logística: } 
		\begin{equation} \label{func_logistica}
			g(u) = \frac{1}{1 + e^{-\beta u}}
		\end{equation}
		Onde $\beta$ é uma constante real que modifica a inclinação da reta.
	}

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=0.5\textwidth]{logistic_func.jpg}
				
				\caption[\small{Função logística \cite{funcoes_ativacao} }]{\label{logistic_func} \small{Neurônio Artificial. Fonte: \cite{funcoes_ativacao}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}
	\item {\textbf{Tangente Hiperbólica: }
		\begin{equation} \label{func_tanh}
			g(u) = \frac{1 - e^{-\beta u}}{1 + e^{-\beta u}}
		\end{equation}
		Onde $-1 \leq g(u) \leq$ para qualquer u e assim como em \ref{func_logistica}, $\beta$ também modifica a inclinação da reta.
	}

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=0.5\textwidth]{tanh.jpg}
				
				\caption[\small{Tangente hiberbólica \cite{tanh} }]{\label{tanh} \small{Tangente Hiperbólica. Fonte: \cite{tanh}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}


	\item {\textbf{Unidade Linear Retificada - ReLU \cite{K_He}:}
		\begin{equation} \label{func_relu}
			g(u) = \max(0, u)
		\end{equation}
		Esta função é linear na parte positiva e zero na parte negativa.
	}

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=0.5\textwidth]{relu.jpg}
				
				\caption[\small{ReLU \cite{relu} }]{\label{relu} \small{ReLU. Fonte: \cite{relu}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}


\end{itemize}

\paragraph{}As funções de ativação \ref{func_logistica} e \ref{func_tanh} são deriváveis em todos os pontos e a \ref{func_relu} só não é derivável no ponto zero, porém contorna-se essa limitação fazendo $g'(0) = 0$. A ReLU tem sido essencial para o estado da arte de redes neurais \cite{relu} \cite{deep_learning_relu} \cite{relu_recomender} \cite{deep_learning_relu2}. A derivada da função de ativação é utilizada pelos algoritmos de treinamento baseados no gradiente do erro assim como será visto mais à frente.

\subsection{Backpropagation}
\paragraph{}O algoritmo de backpropagtion é bastante utilizado no treinamento de de redes neurais e utiliza o gradiente do erro como base dos cálculos, assim como mencionado anteriormente \cite{Bishop} \cite{backprop}. Busca-se mover o vetor dos pesos na direção do mínimo local. A expressão de atualização dos pesos é da seguinte forma:
\begin{equation} \label{grad_desc}
 w^{(\tau + 1)} = w^{(\tau)} - \eta\nabla E_n w^{(\tau)}
\end{equation}

\paragraph{}O qual deve ser repetido até que o erro se torne suficientemente pequeno. O gradiente do erro nessa fórmula é dado por:

\begin{equation}
\nabla E^{(\tau)} = \frac{\partial E}{\partial W_{ji}^{(\tau)}} = \frac{\partial E}{\partial Y_{j}^{(\tau)}} \cdot \frac{\partial Yj^{(\tau)}}{\partial u_j^{(\tau)}} \cdot \frac{\partial u_j^{(\tau)}}{\partial W_{ji}^{(\tau)}}
\end{equation}

\paragraph{}Têm-se como ideia principal do mesmo avaliar quanto que um determinado peso em uma camada influência no erro da saída e assim, modificá-lo de forma a tornar esse erro menor. Um ponto importante para o sucesso do algoritmo é a normalização da entrada, visto que diminui o tempo de convergência.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{grad_desc.jpg}
				
				\caption[\small{Tangente hiberbólica \cite{relu} }]{\label{grad_desc_fig} \small{Gradiente Descendente desnormalizado e normalizado. Fonte: \cite{relu}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}

\subsection{Rede perceptron multicamadas - MLP}
\paragraph{}Assim como no cérebro, os neurônios artificiais podem ser agrupados em estrutura mais complexas. Para uma camada inicial com N entradas têm se na J-ésima saída:
\begin{equation}
Y_{j}^{(1)} = g(\sum_{i = 0}^{N} W_{ji}^{(1)} \cdot X_i)
\end{equation}

\paragraph{}Nas camadas seguintes utiliza-se a saída da camada anterior (com $M$ neurônios) como entrada na camada atual. Na fórmula busca-se obter a saída para o $P$-ésimo neurônio da camada $H$. 
\begin{equation}
Y_{P}^{(H)} = g(\sum_{i = 0}^{M} W_{pi}^{(H)} \cdot Y_{i}^{(H-1)})
\end{equation}

\paragraph{}As redes MLP tem sido utilizadas em diferentes classes de problemas como classificação de elementos e previsão de séries temporais \cite{apostilaCaloba} \cite{ivan_nunes}  \cite{mlp_atmosfera}. Com o grande crescimento do número de dados disponível para utilização e o desenvolvimento das tecnologias computacionais, têm-se atualmente redes com muitas camadas e neurônios em busca de obter maior capacidade de separação, previsão, além de poder obter informações relevantes sobre neurônios intermediários da rede \cite{deep_learning1} \cite{deep_learning_book} \cite{microsoft_dl}.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=0.7\textwidth]{mlp.jpg}
				
				\caption[\small{Rede Perceptron Multicamadas \cite{relu} }]{\label{mlp} \small{Rede Perceptron Multicamadas. Fonte: \cite{mlp}}}
				
			\end{center}	
		}
		
	\end{center}
	
\end{figure}

\subsection{Treinamento} \label{treinamento_mlp}
\paragraph{}Para que a rede consiga de fato "aprender" com os dados é necessário realizar o treinamento. Para que o mesmo seja bem sucedido deve-se atentar para alguns fatores como: 
\begin{itemize}
	\item {\textbf{Inicialização dos pesos: }Os pesos não devem se iniciados com o mesmo valor, pois isto faria com que cada neurônio interprete a entrada da mesma forma, gerando então uma estrutura simétrica \cite{relu} \cite{yam} \cite{ryanhsiao}}.
	
	\item {\textbf{Função custo: } Há necessidade de definir qual função de custo será utilizada na avaliação dos resultados da rede. A função mais comum é o erro médio quadrático - \textit{MSE}, porém dependendo da análise que se deseja fazer e do problema a ser resolvido, outras funções podem ser utilizadas como a o erro médio quadrático - \textit{RMSE}, erro absoluto -\textit{MAE} e acurácia - \textit{ACC} \cite{tccDanilo}}.
		
	\item {\textbf{Curva de aprendizado: }É comum também utilizar um gráfico do erro na saída em função da época de treinamento para o conjunto de treinamento e validação. Através do mesmo é possível observar características como overfitting e underfitting e selecionar o conjunto de pesos que tem o melhor compromisso \cite{data_overfit}.}
		
	\item {\textbf{Quantidade de dados $X$ complexidade da rede: } Outro fator importante a ser observado é a quantidade de dados disponível para treinamento, visto que quanto maior a complexidade estrutural da rede, maior a capacidade de gerar funções complexa, portanto torna-se necessário uma maior quantidade de dados para que a mesma seja treinada sem o efeito de overfitting.}
	
	\item {\textbf{Taxa de aprendizado: }Caso o fator $\eta$ da fórmula \ref{grad_desc} seja um valor muito grande, o algoritmo não conseguirá convergir para um mínimo, porém se $\eta$ for um número muito grande, o treinamento pode levar muita épocas até convergir. Cabe então a quem especifica os parâmetros da rede neural escolher um $\eta$ adequado de forma com que a convergência ocorra e não demore demais.}
	\begin{figure}[H]
		\begin{center}
			{
				\begin{center}
					
					\includegraphics[width=0.7\textwidth]{learning_rate.jpg}
					
					\caption[\small{Influência da taxa de aprendizado \cite{grad_desc} }]{\label{l_rate} \small{Influência da taxa de aprendizado. Fonte: \cite{grad_desc}}}
					
				\end{center}	
			}
			
		\end{center}
		
	\end{figure}
	
	\item {\textbf{Divisão dos dados de entrada: }Uma prática comum para se obter resultados consistentes é dividir os dados em um conjunto de testes e outro de validação, de forma que o conjunto de testes não seja usado no treinamento, sendo assim usado para verificar o quão bom são os resultados da rede para dados desconhecidos. Outra prática comum é dividir o conjunto de treinamento em treino e validação e utilizar a validação cruzada, de forma a realizar vários treinos com a mesma arquitetura, permitindo obter melhores resultados no treinamento  \cite{crossValidation}.}
		\begin{figure}[H]
		\begin{center}
			{
				\begin{center}
					
					\includegraphics[width=0.7\textwidth]{validacao_cruzada.jpg}
					
					\caption[\small{Validacao Cruzadas \cite{validacao_cruzada} }]{\label{validacao_cruzada} \small{Validação cruzada. Fonte: \cite{validacao_cruzada}}}
					
				\end{center}	
			}
			
		\end{center}
		
	\end{figure}
	


\end{itemize}


