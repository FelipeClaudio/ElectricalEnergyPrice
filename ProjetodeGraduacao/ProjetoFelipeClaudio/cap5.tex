\paragraph{}Neste capítulo, são mostrados os resultados obtidos através da aplicação do método descrito no capítulo anterior. Serão detalhados as características dos sinais utilizados assim como os valores dos parâmetros aplicados em cada algoritmo. Alguns resultados obtidos serão expostos no apêndice para facilitar a leitura.

\section{Pré-Processamento}
\paragraph{}Antes de poder utilizar o sinais obtidos no treinamento da rede, fez-se necessário selecionar quais sinais seriam realmente fornecidos como entrada para o modelo e quantos atrasos temporais seriam necessários para determinar a saída. Além disso, houve necessidade de extrair a componente residual do PLD e normalizar os dados. Cada um desses tópicos será detalhado nos parágrafos a seguir.

\subsection{Seleção dos sinais de entrada}
\paragraph{}Os sinais de entrada foram selecionados conforme a seguinte matriz de autocorrelação abaixo:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{corr_plot_pt.jpg}
				
				\caption[\small{Correlação dos dados de entrada.}]{\label{correlacaoDadosEntrada} \small{Correlação dos dados de entrada.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Observou-se alta correlação negativa entre a energia produzida pela hidroelétricas e térmicas. Isso ocorre pelo fato da energia gerada pelas termoelétricas ser a principal substituta para a energia proveniente de usinas térmicas. Sendo assim, decidiu-se então remover a série da energia gerada pelas UTEs de forma a remover a redundância dos dados fornecidos.

\paragraph{}Outra correlação forte observada é a existente entre a ENA, as vazões afluentes e as vazões afluentes úteis. Uma possível explicação para o fato observado é a de todas as variáveis tem um objetivo em comum: calcular quanto de energia pode ser gerada dado uma quantidade de água presente na bacia.

\paragraph{}Por fim, é observada alta correlação entre ENA e a energia produzida pelas usina hidroelétricas. Isso é esperado, pois a ENA é um indicativo de quanta energia pode ser gerada através de meios hidráulicos. 

\subsection{Seleção dos atrasos do sinal de saída}
\paragraph{}O gráfico de autocorrelação expressa de forma numérica uma relação linear entre o valor atual e os atrasos. Com isso, têm-se os atrasos com maior importância na formação do sinal. Foram selecionados os pontos que tinham correlação maior ou próximo do limite do intervalo de 95\% de confiança.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{autocorrelation_PLD.jpg}
				
				\caption[\small{Autocorrelação do PLD.}]{\label{autoCorrelacaoPLD} \small{Autocorrelação do PLD.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Os atrasos obtidos através dessas análises foram replicados para os sinais da entrada, podendo assim definir quantos atrasos seriam necessários para obter informação suficiente para reconstruir a saída. Como conclui-se pelo gráfico que até 20 atrasos temporais são necessários para representar o sinal, o \textit{conjunto de dados} de 48 pontos foi reduzido a 28 pontos.

\subsection{Tendência}
\paragraph{}Para a definição do parâmetro $W$, responsável pelo tamanho da janela utilizada no processamento, fez-se um gráfico do MSE pelo tamanho da janela conforme visto na figura \ref{mseTrend}:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{mseComparation_trend_pt.jpg}
				
				\caption[\small{Análise do MSE pelo tamanho da janela na extração da tendência.}]{\label{mseTrend} \small{Análise do MSE pelo tamanho da janela na extração da tendência.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}Tendo como base o gráfico acima, observou-se que a extração proposta em \ref{maLinFit} obteve os melhores resultados (na figura \ref{mseTrend}) e selecionou-se $W=12$. O parâmetro $K$ foi definido como $K=5$ de forma empírica, buscando obter uma transição suave entre a regressão linear e a média móvel. Aplicando esse filtro obteve-se o seguinte resultado para a extração da tendência:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_trend_pt.jpg}
				
				\caption[\small{Histograma e FFT da tendência obtida.}]{\label{fftAndDistTrend} \small{Histograma e FFT da tendência obtida.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}No gráfico acima é possível ver que, assim como esperado, a tendência do sinal possui componentes acentuadas na alta frequência. Já no gráfico de distribuição, observa-se que o preço no sinal está concentrado em 2 patamares, sendo eles: 100-200 R\$/MWh e 300-400 R\$/MWh.

\subsection{Sazonalidade}
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{mseComparation_tseasonal_pt.jpg}
				
				\caption[\small{Análise do MSE pelo tamanho da janela na extração da sazonalidade.}]{\label{mseSazonal} \small{Análise do MSE pelo tamanho da janela na extração da sazonalidade.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}Nesse caso, observou-se que existe um mínimo local em $T=6$ e um mínimo global em $T=12$. Escolheu se o $T=6$ por ser um múltiplo comum dos dois. Entre as duas análises, a que trouxe os melhores resultados foi a que utilizou somente a média móvel (na figura \ref{fftAndDistSazonal}). O resultado mostra que os eventos sazonais que influenciam o preço do PLD são de característica anual majoritariamente. Finalmente obteve-se como resultado da extração os seguintes gráficos:

\paragraph{}Na figura \ref{fftAndDistSazonal} é possível ver que a distribuição do erro está centrada próxima de $0$ R\$/MWh. No gráfico da FFT, observa-se que diferentemente da FFT vista extração do ciclo senoidal, existe um pico por volta de 0.18 rad/amostra. Isso era é esperado, uma vez que a parte de baixa frequência foi removida na extração anterior. 

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_seasonal_pt.jpg}
				
				\caption[\small{Histograma e FFT da sazonalidade obtida.}]{\label{fftAndDistSazonal} \small{Histograma e FFT da sazonalidade obtida.}}
				
			\end{center}	
		}	
	\end{center}	
\end{figure}

\subsection{Ciclos Senoidais e Resíduo}
\paragraph{}Após o processamento descrito acima, obtém sinal $s_{2t}=cs_t+res_t$, o qual tem a seguinte distribuição e FFT.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_residual_pt.jpg}
				
				\caption[\small{Análise do MSE pelo tamanho da janela na extração da sazonalidade.}]{\label{fftAndDistCS} \small{Análise do MSE pelo tamanho da janela na extração da sazonalidade.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}


\paragraph{}A distribuição observada está centrada em $0$ R\$/MWh e, dentre os picos observados na FFT, o com maior valo absoluto é o que está presente na frequência $w=0.10869$ rad/amostra. Sendo assim, a extração do resíduo de foi feita com um filtro Notch na maior frequência observada e $Q=0.01$ removendo então a frequência com maior energia na transformada de Fourier. Após este processamento, obteve-se os seguintes resultados:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_residualFiltered_pt.jpg}
				
				\caption[\small{Distribuição e FFT após extração da componente de maior energia.}]{\label{fftAndDistFilt} \small{Distribuição e FFT após extração da componente de maior energia.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}É possível observar que a distribuição continuou centrada em torno de $0$ R\$/MWh, porém com um formato diferente. Além disso, a FFT mostra que as magnitudes estão espalhadas por todo o espectro ao invés de concentradas em poucas frequências. Isso atende à expectativa de que o ruído obtido ao final do processamento deveria estar linearmente distribuído pelo espectro.

\paragraph{}Ao final do processo, os seguintes resultados foram obtidos:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{resultPld_tsa_pt.jpg}
				
				\caption[\small{Resultado final com as componentes separadas utilizando o método descrito acima.}]{\label{resultado_Extracao} \small{Resultado Final com as componentes separadas utilizando o método descrito acima.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\section{Treinamento das redes neurais}
\paragraph{}Os resultados dos treinamentos presentes nessa seção seguiram a metodologia descrita em \ref{treinamentoRedes}. Sendo assim, o primeiro treinamento realizado foi para determinar a estrutura da rede de estimação da saída para o mês atual.

\subsection{Treinamento da rede para obter a saída no mês atual}
\paragraph{}Para o treinamento rede para a saída atual, obteve-se o seguinte gráfico de RMSE pelo número de neurônios no conjunto de treinamento:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{rmse_val_set_t0.jpg}
				
				\caption[\small{RMSE pelo número de neurônios no conjunto de validação no mês atual.}]{\label{mseValT0} \small{RMSE pelo número de neurônios no conjunto de validação no mês atual.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}


\paragraph{}No conjunto de testes o resultado foi o seguinte:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{rmse_test_set_t0.jpg}
				
				\caption[\small{RMSE pelo número de neurônios no conjunto de teste no mês atual.}]{\label{mseTestT0} \small{RMSE pelo número de neurônios no conjunto de teste no mês atual.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Esperava-se que o gráfico do RMSE pelo número de neurônios na camada intermediária fosse decrescente, mas o resultado obtido oscilou em torno do valor médio do RMSE (em torno e 0.22). Isso pode ser uma das consequências da pouca quantidade de dados tanto para teste quanto para a validação. Redes neurais geralmente necessitam de grande conjuntos de dados para que se possa definir os pesos das conexões sinápticas de forma correta. Sendo assim, esse gráfico não foi suficiente para determinar qual estrutura seria utilizada para realizar as previsões. Para poder ranquear as estruturas e, então, escolher a utilizada nas previsões, fez a seguinte tabela. Os dados mostrado a seguir contém as 5 melhores estruturas de redes ranqueadas pelo critério $\epsilon_3$ definido anteriormente:
\begin{table}[H]
	
	\begin{center}	
		\caption{Resultados obtidos com as redes no conjunto de dados de validação no mês atual.}		
		\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline \label{table:tabelaT0}
			 
			\textbf{\#neurônios} & \textbf{RMSE} & \textbf{STD} & \textbf{$a$ (média)} & \textbf{$\epsilon_1$} & \textbf{$b$ (média)} & \textbf{$\epsilon_2$} & \textbf{$\epsilon_3$}\\ \hline \vspace{-1.0mm}61 &64,435 & 61,180 &  0,998 & 0,008 & -0,007 & 0,175 & 0,184 \\ \hline
			38 & 66,896 & 63,894 & 1,005 & 0,019 & -0,003 & 0,175 & 0,194 \\ \hline
			97 & 63,509 & 61,957 & 1,000 & 0,001 & 0,046 & 0,224 & 0,225 \\ \hline
			77 & 56,788 & 54,954 & 1,003 & 0,010 & 0,044 & 0,224 & 0,234 \\ \hline
			92 & 55,370 & 53,135 & 0,983 & 0,063 & 0,009 & 0,224 & 0,287 \\ \hline
		\end{tabular}	
	\end{center} 
\end{table}

\paragraph{}E com isso o modelo com 61 neurônios foi escolhido. O treinamento dessa estrutura obteve os seguintes erros pelo número de épocas e por subconjuntos:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{convergence_t0.jpg}
				
				\caption[\small{Erro pelo número de época e por subconjunto no mês atual.}]{\label{convT0} \small{Erro pelo número de época e por subconjunto no mês atual.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Apesar de usar um fator de treinamento menor do que o padrão, ainda assim o algoritmo AdaDelta teve dificuldade em convergir para um valor de RMSE Assim como esperado, o erro no conjunto de validação foi maior que no conjunto de teste.

\paragraph{}E os seguintes resultados foram obtidos:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{sinal_completo_t0.jpg}
				
				\caption[\small{Comparação entre o PLD médio e o resultado obtido no mês atual.}]{\label{completoT0} \small{Comparação entre o PLD médio e o resultado obtido no mês atual.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Os 3 últimos pontos são do conjunto de dados de teste. Observa-se que a rede não conseguiu prevê-los tão bem quanto os pontos do conjunto de treinamento, assim como esperado.

\paragraph{}Dado a pouca quantidade de dados, a rede não obteve o comportamento esperado nos treinamentos por validação cruzada, porém o resultado obtido mostrou que a mesma conseguiu mapear bem a entrada na saída. Sendo assim, viu-se que a rede está sendo treinada de forma coerente para obter $y(t)$ a partir de $x(t)$. Esse caso também será utilizado como base para as previsões, pois espera-se que o erro para $N$ passos a frente seja sempre maior ou igual ao caso base.

\subsection{Treinamento da rede para obter a saída um mês a frente}
\paragraph{}Seguindo o procedimento previamente determinado, obteve-se os seguintes resultados para a previsão do PLD para 1 mês a frente:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{rmse_val_set_t1.jpg}
				
				\caption[\small{RMSE pelo número de neurônios no conjunto de validação no mês seguinte.}]{\label{rmseValT1} \small{RMSE pelo número de neurônios no conjunto de validação no mês seguinte.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}


\paragraph{}No conjunto de teste o resultado foi o seguinte:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{rmse_test_set_t1.jpg}
				
				\caption[\small{RMSE pelo número de neurônios no conjunto de teste no mês seguinte.}]{\label{rmseTestT1} \small{RMSE pelo número de neurônios no conjunto de teste no mês seguinte.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Novamente observou-se que o gráfico de RMSE pelo número de neurônios não seguiu um formato decrescente contínuo. Sendo assim, utilizou-se a tabela com informações adicionais sobre cada treinamento para auxiliar a escolha do melhor modelo. Os resultados são vistos a seguir:

\begin{table}[H]
	
	\begin{center}
		\caption{Resultados obtidos com as redes no conjunto de dados de validação no mês seguinte.}	
		\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline \label{table:tabelaT1}
			
			\textbf{\#neurônios} & \textbf{RMSE} & \textbf{STD} & \textbf{$a$ (média)} & \textbf{$\epsilon_1$} & \textbf{$b$ (média)} & \textbf{$\epsilon_2$} & \textbf{$\epsilon_3$}\\ \hline \vspace{-1.0mm}63 & 82,911 & 69,521 & 0,993 & 0,002 & 0,005 & 0,003 & 0,004 \\ \hline
			71 & 88,327 & 74,076 & 0,985 & 0,004 & -0,027 & 0,014 & 0,018 \\ \hline
			25 & 93,041 & 73,840 & 0,966 & 0,008 & 0,020 & 0,010 & 0,018 \\ \hline
			50 & 103,137 & 93,552 & 0,927 & 0,018 & 0,032 & 0,016 & 0,034 \\ \hline
			51 & 94,937 & 81,015 & 0,860 & 0,034 & 0,000 & 0,000 & 0,034 \\ \hline
		\end{tabular}
	\end{center} 
\end{table}
\paragraph{}E com isso o modelo com 63 neurônios foi escolhido. O treinamento dessa estrutura obteve os seguintes erros pelo número de épocas:


\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{convergence_t1.jpg}
				
				\caption[\small{Erro pelo número de épocas e por subconjunto no mês seguinte.}]{\label{convT1} \small{Erro pelo número de épocas e por subconjunto no mês seguinte.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}E obteve-se os seguintes resultados:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{sinal_completo_t1.jpg}
				
				\caption[\small{Comparação entre o sinal original e o resultado obtido no mês seguinte.}]{\label{completoT1} \small{Comparação entre o sinal original e o resultado obtido no mês seguinte.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Uma rápida análise qualitativa mostra que a previsão do ruído do sinal fez com que o erro obtido no conjunto de treino fosse menor, porém no conjunto de testes (últimos 3 pontos), o erro foi maior do que o modelo sem ruído.

\paragraph{}Para essa previsão, foi treinada uma rede para reduzir o erro de estimação usando como entrada os dados já mencionados anteriormente. Os erros de estimação entre o sinal reconstruído e o original foram utilizados como alvos da rede. Obteve-se então os seguintes resultados:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{rmse_val_set_t1_error.jpg}
				
				\caption[\small{RMSE pelo número de neurônios no conjunto de validação no mês seguinte com correção de erro.}]{\label{mseValT1Error} \small{RMSE pelo número de neurônios no conjunto de validação no mês seguinte com correção de erro.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}


\paragraph{}No conjunto de teste o resultado foi o seguinte:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{rmse_test_set_t1_error.jpg}
				
				\caption[\small{RMSE pelo número de neurônios no conjunto de teste no mês seguinte com correção de erro.}]{\label{mseTestT1Error} \small{RMSE pelo número de neurônios no conjunto de teste no mês seguinte com correção de erro.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\begin{table}[H]
	
	\begin{center}
		\caption{Resultados obtidos com as redes no conjunto de dados de validação no mês seguinte com correção de erro.}			
		\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline \label{table:tabelaT1Erro}
			
			\textbf{\#neurônios} & \textbf{RMSE} & \textbf{STD} & \textbf{$a$ (média)} & \textbf{$\epsilon_1$} & \textbf{$b$ (média)} & \textbf{$\epsilon_2$} & \textbf{$\epsilon_3$}\\ \hline \vspace{-1.0mm}90 & 126,678 & 101,233 & 1,029 & 0,001 & -0,001 & 0,000 & 0,001  \\ \hline
			14 & 130,352 & 98,738 & 0,973 & 0,001 & -0,002 & 0,000 & 0,001  \\ \hline
			46 & 137,971 & 99,784 & 1,017 & 0,001 & -0,017 & 0,001 & 0,002  \\ \hline
			76 & 136,014 & 105,032 & 0,982 & 0,001 & 0,057 & 0,003 & 0,004  \\ \hline
			60 & 123,420 & 98,844 & 1,070 & 0,002 & -0,031 & 0,002 & 0,004  \\ \hline
		\end{tabular}
	\end{center} 
\end{table}

\paragraph{}E com isso o modelo com 90 neurônios foi escolhido. O treinamento dessa estrutura obteve os seguintes erros pelo número de épocas:


\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{convergence_t1_error.jpg}
				
				\caption[\small{Erro pelo número de épocas e por subconjunto no mês seguinte com correção de erro.}]{\label{convT1erro} \small{Erro pelo número de épocas e por subconjunto no mês seguinte com correção de erro.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}E finalmente obteve-se os seguintes resultados:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{sinal_completo_t1_error.jpg}
				
				\caption[\small{Comparação entre o sinal original e o resultado obtido no mês seguinte com correção de erro.}]{\label{completoT1Error} \small{Comparação entre o sinal original e o resultado obtido no mês seguinte com correção de erro.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{original_pred_rede_erro_hist.jpg}
				
				\caption[\small{Histograma de previsão sem e com a correção de erro.}]{\label{histErro} \small{Histograma de previsão sem e com a correção de erro.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Pelo histograma é possível ver que a rede de correção do erro de estimação diminuiu o erro máximo e mínimo, porém a estrutura sem a correção do erro tem maior concentração de pontos próximos do zero. Sendo assim, espera-se que a saída com a correção de erro erre mais, porém com discrepância menor, enquanto espera-se que sem a correção de erro o resultado seja melhor na maioria das vezes, podendo correr o risco de errar muito em alguns pontos.

\paragraph{}Realizando novamente uma análise qualitativa, observa-se que o sinal com a rede de correção do erro não parece trazer resultados melhores. O resultado discutido no parágrafo acima é, de fato, observável no gráfico. Cabe a quem for utilizar analisar se compensa mais errar menos na média, porém ter uma chance de errar muito em casos extremos ou errar um pouco mais na média e ter o erro dentre de uma faixa menor.

\subsection{Treinamento da rede para obter a saída para vários meses a frente}
\paragraph{}A rede para vários meses à frente foi treinada de forma similar ao observado anteriormente, porém nesse caso, observou-se somente a parte residual e não foi treinada uma rede secundária para corrigir o erro de estimação em cada caso.

\paragraph{}A partir dos resultados, gerou-se o seguinte gráfico que mostra o erro da rede em relação ao sinal original para diferentes números de passos a frente:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{mean_std_test_best_prev.jpg}
				
				\caption[\small{Erro no sinal residual pelo número de passos no conjunto de dados de teste.}]{\label{rmsePassosTeste} \small{Erro no sinal residual pelo número de passos no conjunto de dados de teste.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{mean_std_comp_best_prev.jpg}
				
				\caption[\small{Erro no sinal residual pelo número de passos no conjunto de dados completo.}]{\label{rmsePassosComp} \small{Erro no sinal residual pelo número de passos no conjunto de dados de completo.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}A tabela com os dados utilizados na seleção de cada modelo, o gráfico de convergência e os resultados obtidos  estão presente no apêndice A.

\paragraph{}Assim como o esperado, tanto o erro quanto o desvio padrão aumentam com o número de passos a frente, salvo algumas exceções. Além disso, após o quinto mês, os erros de previsão aumentam bastante, tornando pouco informativa a previsão para os meses posteriores

\paragraph{}Sendo assim, a previsão para muitos passo a frente traz um risco maior para a análise. Cabe a quem for usar mensurar quanto de risco pode ser tolerado baseado nesses gráficos.

\paragraph{}Ainda assim cabe ressaltar que o a análise foi feita somente para a parte residual. Provavelmente ao reconstruir o PLD, os erros ainda devem aumentar, pois serão somados os erros de estimação da tendência, sazonalidade e ciclos senoidais. A estratégia da rede para a correção dos erros pode ser aplicada para cada um dos casos buscando deixar a distribuição do erro mais concentrada em torno do zero.

\paragraph{}Ao final do processo obteve-se um modelo de estimação do PLD para o mês atual que foi utilizado como base para as análises seguintes. Além disso, criou-se um método de ranqueamento dos modelos com baseada em parâmetros como o coeficiente angular e offset no \textit{scatter plot}. Outra abordagem explorada nesse texto foi uma rede para corrigir o erro de uma primeira rede. 

\paragraph{}O resultado final do trabalho foi, então, a definição de um método para avaliar estruturas de redes neurais em casos onde há poucos dados. Este método pode ser usado e replicado em outras aplicações. Os gráficos \ref{rmsePassosTeste} e \ref{rmsePassosComp} mostram que, assim como esperado para um modelo de previsão com número de passos variáveis, o erro cresce conforme a necessidade de prever eventos mais à frente.
