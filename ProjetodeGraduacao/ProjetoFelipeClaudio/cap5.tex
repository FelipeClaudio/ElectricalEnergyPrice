\paragraph{}Neste capítulo são mostrados os resultados obtidos através da aplicação do método descrito no capítulo anterior.. Serão detalhados as características dos sinais utilizados assim como os valores dos parâmetros aplicados em cada algoritmo. Alguns resultados obtidos serão expostos no apêndice para facilitar a leitura.

\section{Aquisição dos dados}
\paragraph{}Os dados utilizados e suas respectivas fontes podem ser observados na tabela \ref{table:DadosDeEntrada}. No início do trabalho definiu-se que o foco seria a região sudeste, sendo assim, todos os dados utilizados foram filtrados para a região SE/CO. Os dados provenientes da ONS foram baixados direto do site no formato \textit{Comma Separated Values} - CSV.

\paragraph{} Para facilitar o processamento, foram retiradas todas as colunas que não fossem a data no formato "mês (por extenso) ano". Essas foram então renomeadas para "month" e "value" e o valor do dado referido (ex: MWh produzidos por usinas hidroelétricas no mês), facilitando o desenvolvimento do código. 

\paragraph{}Dado que as regras para o cálculo do PLD variam durante os anos, utilizou-se somente os dados no período entre 01/2015 e 12/2018 de modo a tentar reduzir ao máximo esse efeito. Sendo assim, o \textit{dataset} possui 48 somente pontos.

\section{Pré-Processamento}
\paragraph{}Antes de poder utilizar o sinais obtidos no treinamento da rede, fez-se necessário selecionar quais sinais seriam realmente fornecidos como entrada para o modelo e quantos atrasos temporais seriam necessários para determinar a saída. Além disso há a necessidade de extrair a componente residual do PLD e normalizar os dados. Cada um desses tópicos será detalhado nos parágrafos a seguir.

\subsection{Seleção dos sinais de entrada}
\paragraph{}Os sinais de entrada foram selecionado conforme a seguinte matriz de autocorrelação abaixo:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{corr_plot_pt.jpg}
				
				\caption[\small{Correlação dos dados de entrada.}]{\label{correlacaoDadosEntrada} \small{Correlação dos dados de entrada.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Observou-se alta correlação negativa entre a energia produzida pela hidroelétricas e térmicas. Isso ocorre pelo fato da energia gerada pelas termoelétricas ser a principal substituta para a energia proveniente de usinas térmicas. Sendo assim, decidiu-se então remover a série da energia gerada pelas UTEs de forma a remover a redundância dos dados fornecidos.

\subsection{Seleção dos atrasos do sinal de saída}
\paragraph{}O gráfico de autocorrelação expressa de forma numérica uma relação linear entre o valor atual e os atrasos. Com isso, têm-se os atrasos com maior importância na formação do sinal. Assim como descrito no capítulo anterior, foram selecionados os pontos que tinham correlação maior ou próximo do limite do intervalo de 95\% de confiança.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{autocorrelation_PLD.jpg}
				
				\caption[\small{Autocorrelação do PLD.}]{\label{autoCorrelacaoPLD} \small{Autocorrelação do PLD.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Os atrasos obtidos através dessas análises foram replicados para os sinais da entrada, podendo assim definir quantos atrasos seriam necessários para obter informação suficiente para reconstruir a saída. Como conclui-se pelo gráfico que até 20 atrasos temporais são necessários para representar o sinal, o \textit{dataset} de 48 pontos foi reduzido a 28 pontos.

\subsection{Tendência}
\paragraph{}Para a definição do parâmetro $W$, responsável pelo tamanho da janela utilizada no processamento, fez-se um gráfico do MSE pelo tamanho da janela conforme visto na figura a seguir:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{mseComparation_trend_pt.jpg}
				
				\caption[\small{Análise do mse pelo tamanho da janela na extração da tendência.}]{\label{mseTrend} \small{Análise do mse pelo tamanho da janela na extração da tendência.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}Tendo como base o gráfico acima, observou-se que a extração proposta em \ref{maLinFit} obteve os melhores resultados e o selecionou-se $W=12$. O parâmetro $K$ foi definido como $K=5$ de forma empírica, de forma a obter uma transição suave entre a regressão linear e a média móvel. Aplicando esse filtro obteve-se o seguinte resultado para a extração da tendência:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_trend_pt.jpg}
				
				\caption[\small{Distribuição residual e FFT da tendência.}]{\label{fftAndDistTrend} \small{Distribuição residual e FFT do sinal extraído.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}


\subsection{Sazonalidade}
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{mseComparation_tseasonal_pt.jpg}
				
				\caption[\small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}]{\label{mseSazonal} \small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}Nesse caso observou-se que existe um mínimo local em $T=6$ e um mínimo global em $T=12$. Escolheu se o $T=6$ por ser um múltiplo comum dos dois. Entre as duas análises, a que trouxe melhores resultados foi a que utilizou somente a média móvel. Finalmente obteve-se como resultado da extração os seguintes gráficos:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_seasonal_pt.jpg}
				
				\caption[\small{Distribuição residual e FFT da sazonalidade.}]{\label{fftAndDistSazonal} \small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}}
				
			\end{center}	
		}	
	\end{center}	
\end{figure}

\subsection{Ciclos Senoidais e Resíduo}
\paragraph{}Após o processamento descrito acima, obtém se o sinal $s_{2t}=cs_t+res_t$, o qual tem a seguinte distribuição e FFT.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_residual_pt.jpg}
				
				\caption[\small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}]{\label{fftAndDistCS} \small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}


\paragraph{}Para a extração do resíduo de fato utilizou-se um filtro notch com frequência $w=0.10869$ rad/amostra e $Q=0.01$ removendo então a frequência com maior energia na transformada de Fourier. Obtendo a seguinte distribuição e FFT:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_residualFiltered_pt.jpg}
				
				\caption[\small{Distribuição e FFT após extração da componente de maior energia.}]{\label{fftAndDistFilt} \small{Distribuição e FFT após extração da componente de maior energia.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}Ao final do processo, os seguintes resultados foram obtidos:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{resultPld_tsa_pt.jpg}
				
				\caption[\small{Resultado Final com as componentes separadas utilizando o método descrito acima.}]{\label{resultado_Extracao} \small{Resultado Final com as componentes separadas utilizando o método descrito acima.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\section{Treinamento das redes neurais}
\paragraph{}O treinamento foi feito utilizando validação cruzada com 8 folds no dataset de treinamento. Foram deixados 3 pontos da série temporal para realizar o teste. Para cada fold foram feitas 3 inicializações aleatórias utilizando o método chamado \textit{he uniform}, o qual está descrito em \cite{K_He}.

\paragraph{}Devido ao número de atrasos relevantes obtidos pelo gráfico de autocorrelação (20 atrasos), o \textit{dataset} se reduziu a 28 pontos, dos quais os 3 últimos foram separados para teste e os outros 25 foram utilizados na validação cruzada. Essa será feita com valores entre 3 e 8 folds.

\paragraph{}Após a extração residual, os dados são normalizados para facilitar a convergência do treinamento, assim como mostrado em \ref{treinamento_mlp}. 

\paragraph{}Dado que as entradas foram selecionadas e previamente processadas, restou definir a arquitetura da rede neural utilizada. Devido à simplicidade e a boa capacidade de solução de problemas, foi utilizada a rede Perceptron Multicamadas com somente uma camada intermediária. Foi definido para a camada de entrada e a intermediária que a função de ativação utilizada seria a ReLU, dado a velocidade de processamento e os bons resultados obtidos em pesquisas recentes \ref{reluSucesso}. Para a camada de saída, a função de ativação escolhida foi a linear, para que se possa construir a série temporal. O algoritmo de aprendizado utilizado foi o adadelta com learning rate de $\alpha = 0.01$ \cite{adadelta} por conta dos bons resultados obtidos no treinamento e rápida convergência para o estado final.

\paragraph{}O $\alpha$ foi escolhido de forma a fazer com que o gráfico de erro no dataset de treino pelo número de neurônios convergisse para todos os folds utilizados na validação cruzada. Foi utilizado o critério de parada antecipada \textit{early stop} para que caso a rede não melhorasse o erro obtido em 25 épocas, o processamento seria então interrompido.

\paragraph{}Apesar das definições acima, ainda há necessidade de definir a quantidade de neurônios na camada intermediária. Foi feito então um treinamento variando o número de neurônios entre 1 e 90 e a partir disso gerou-se um gráfico com o RMSE pelo número de neurônios no conjunto de validação e de teste, conforme a figura abaixo:

\paragraph{}[Inserir a figura do rmse]

\subsection{Treinamento da rede para obter a saída no mês atual}
\paragraph{}Para o treinamento rede para a saída atual, obteve-se o seguinte gráfico de rmse pelo número de neurônios no conjunto de treinamento:
\paragraph{}[MSE NO CONJUNTO treinamento]

\paragraph{}No conjunto de testes o resultado foi o seguinte:
\paragraph{}[MSE NO CONJUNTO de testes]

\paragraph{}As 5 melhores estruturas de redes ranqueadas pelo critério $\epsilon_3$ definido anteriormente são as seguintes:
\begin{table}[h]
	
	\begin{center}
		
		\caption{Dados utilizado no trabalho.}
		
		\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline \label{table:tabelaT0}
			 
			\textbf{\#neurônios} & \textbf{RMSE} & \textbf{STD} & \textbf{$a$ (média)} & \textbf{$\epsilon_1$} & \textbf{$b$ (média)} & \textbf{$\epsilon_2$} & \textbf{$\epsilon_3$}\\ \hline \vspace{-1.0mm}
			
			61 &64,435 & 61,180 &  0,998 & 0,008 & -0,007 & 0,175 & 0,184 \\ \hline
			38 & 66,896 & 63,894 & 1,005 & 0,019 & -0,003 & 0,175 & 0,194 \\ \hline
			97 & 63,509 & 61,957 & 1,000 & 0,001 & 0,046 & 0,224 & 0,225 \\ \hline
			77 & 56,788 & 54,954 & 1,003 & 0,010 & 0,044 & 0,224 & 0,234 \\ \hline
			92 & 55,370 & 53,135 & 0,983 & 0,063 & 0,009 & 0,224 & 0,287 \\ \hline
		\end{tabular}
		
	\end{center} 
\end{table}

\paragraph{}E com isso o modelo com 61 neurônios foi escolhido. O treinamento dessa estrutura obteve os seguintes erros pelo número de épocas:

\paragraph{}[GRAFICO CONVERGÊNCIA]

 \paragraph{}E os seguintes resultados foram obtidos:
\paragraph{}[GRÁFICO DO RESÍDUO ORIGINAL X RESÍDUO PREVISTO]
\paragraph{}[GRÁFICO DO SINAL RECONSTRUÍDO]
\paragraph{}Sendo assim, viu-se que a rede está sendo treinada de forma coerente para obter $y(t)$ a partir de $x(t)$. Esse caso também será utilizado como base para as previsões, pois espera-se que o erro para $N$ passos a frente seja sempre maior ou igual ao caso base.

\subsection{Treinamento da rede para obter a saída um mês a frente}
\paragraph{}Seguindo o procedimento previamente determinado, obteve-se os seguintes resultados para a previsão do PLD para 1 mês a frente:

\paragraph{}[TABELA Critério $\epsilon_3$]

\paragraph{}E com isso o modelo com 63 neurônios foi escolhido. O treinamento dessa estrutura obteve os seguintes erros pelo número de épocas:

\paragraph{}[GRAFICO CONVERGÊNCIA]

\paragraph{}E obteve-se os seguintes resultados:
\paragraph{}[GRÁFICO DO RESÍDUO ORIGINAL X RESÍDUO PREVISTO]
\paragraph{}[GRÁFICO DO SINAL RECONSTRUÍDO]

\paragraph{}Para essa previsão, foi treinada uma rede para reduzir o erro de estimação usando como entrada os dados já mencionados anteriormente. Os erros de estimação entre o sinal reconstruído e o original foram utilizados como alvos da rede. Obteve-se então os seguintes resultados:

\paragraph{}[TABELA Critério $\epsilon_3$]

\paragraph{}E com isso o modelo com 58 neurônios foi escolhido. O treinamento dessa estrutura obteve os seguintes erros pelo número de épocas:

\paragraph{}[GRAFICO CONVERGÊNCIA]
\paragraph{}E finalmente obteve-se os seguintes resultados:
\paragraph{}[GRÁFICO DO RESÍDUO ORIGINAL X RESÍDUO PREVISTO]
\paragraph{}[GRÁFICO DO SINAL RECONSTRUÍDO]

\paragraph{}Pelo histograma é possível ver que a rede de correção do erro de estimação diminuiu o erro máximo e mínimo, porém a estrutura sem a correção do erro tem maior concentração de pontos próximos do zero. Sendo assim, espera-se que a saída com a correção de erro erre mais, porém com discrepância pequena, enquanto espera-se que sem a correção de erro o resultado seja melhor na maioria das vezes, podendo correr o risco de errar muito em alguns pontos.

\paragraph{}Cabe a quem for utilizar analisar se compensa mais errar menos na média, porém ter uma chance de errar muito em casos extremos ou errar um pouco mais na média e ter o erro dentre de uma faixa menor.

\subsection{Treinamento da rede para obter a saída para vários meses a frente}
\paragraph{}A rede para vários meses à frente foi treinada de forma similar ao observado anteriormente, porém nesse caso observou-se somente a parte residual e não foi treinada uma rede secundária para corrigir o erro de estimação em cada caso.

\paragraph{}A partir dos resultados, gerou-se o seguinte gráfico que mostra o erro da rede em relação ao sinal original para diferentes números de passos a frente:

[grafico mse pelo número de passos a frente]

\paragraph{}A tabela com os dados utilizados para a seleção do do modelo, os gráficos de convergência e a de cada modelos estão presente nos apêndices A e B respectivamente. Além disso, o gráfico com a comparação do sinal previsto com o resíduo original pode ser visto no apêndice C.


\paragraph{}Assim como o esperado, tanto o erro quanto o desvio padrão aumentam com o número de passos a frente, salvo algumas exceções. Sendo assim, a previsão para muitos passo a frente traz um risco maior para a análise. Cabe a quem for usar mensurar quanto de risco pode ser tolerado baseado nesses gráficos.

\paragraph{}Ainda assim cabe ressaltar que o a análise foi feita somente para a parte residual. Provavelmente ao reconstruir o PLD, os erros ainda devem aumentar, pois serão somados os erros de estimação da tendência, sazonalidade e ciclos senoidais. A estratégia da rede para a correção dos erros pode ser aplicada para cada um dos casos buscando deixar a distribuição do erro mais concentrada em torno do zero.
