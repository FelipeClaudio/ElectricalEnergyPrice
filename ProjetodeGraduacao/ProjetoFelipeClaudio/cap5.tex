\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{autocorrelation_PLD.jpg}
				
				\caption[\small{Autocorrelação do PLD.}]{\label{autoCorrelacaoPLD} \small{Autocorrelação do PLD.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}


\paragraph{}Os sinais de entrada foram selecionado conforme a seguinte matriz de autocorrelação abaixo:

\paragraph{}Observou-se alta correlação negativa entre a energia produzida pela hidroelétricas e térmicas. Isso ocorre pelo fato da energia gerada pelas termoelétricas ser a principal substituta para a energia proveniente de usinas térmicas. Sendo assim, decidiu-se então remover a série da energia gerada pelas UTEs de forma a remover a redundância dos dados fornecidos.

\paragraph{}Completar seção do processamento do sinal de entrada


\section{Aquisição dos dados}
\paragraph{}Os dados utilizados e suas respectivas fontes podem ser observados na tabela \ref{table:DadosDeEntrada}.

 Para facilitar o processamento, foram retiradas todas as colunas que não fossem a data no formato "mês (por extenso) ano". Essas foram então renomeadas para "month" e "value", respectivamente para facilitar o desenvolvimento do código.
 

 com learning rate de $\alpha = 0.01$ \cite{adadelta} por conta dos bons resultados obtidos no treinamento e rápida convergência para o estado final.
 
 \paragraph{}O treinamento foi feito utilizando validação cruzada com 8 folds no dataset de treinamento. Assim, como mencionado anteriormente, foram deixados 3 pontos da série temporal para realizar o teste.Para cada fold foram feitas 8 inicializações aleatórias utilizando o método chamado \textit{he uniform}, o qual está descrito em \cite{K_He}.
 

 
 \paragraph{}Dado que as regras para o cálculo do PLD variam durante os anos, utilizou-se somente os dados no período entre 01/2015 e 12/2018 de modo a tentar reduzir ao máximo esse efeito. Sendo assim, o \textit{dataset} possui 48 pontos.
 
 \paragraph{}Devido ao número de atrasos relevantes obtidos pelo gráfico de autocorrelação (21 atrasos), o \textit{dataset} se reduziu a 28 pontos, dos quais os 3 últimos foram separados para teste e os outros 24 foram utilizados na validação cruzada. Essa será feita com valores entre 3 e 8 folds.
 
 \paragraph{}Após a extração residual, os dados são normalizados para facilitar a convergência do treinamento, assim como mostrado em \ref{treinamento_mlp}. 
 
 \paragraph{}No início do trabalho definiu-se que o foco seria a região sudeste, sendo assim, todos os dados utilizados foram filtrados para a região SE/CO. Os dados provenientes da ONS foram baixados direto do site no formato \textit{Comma Separated Values} - CSV.

[ADICIONADO]

\paragraph{}Neste capítulo são mostrados os resultados obtidos através da aplicação do método descrito no capítulo anterior. Alguns resultados obtidos serão expostos no apêndice para facilitar a leitura.

\section{Pré-Processamento}

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{mseComparation_trend_pt.jpg}
				
				\caption[\small{Análise do mse pelo tamanho da janela na extração da tendência.}]{\label{mseTrend} \small{Análise do mse pelo tamanho da janela na extração da tendência.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}Tendo como base o gráfico visto acima, observou-se que a extração proposta em \ref{maLinFit} obteve os melhores resultados e o selecionou-se $W=12$. O parâmetro $K$ foi definido como $K=5$ de forma empírica, de forma a obter uma transição sauve entre a regressão linear e a média móvel. Aplicando esse filtro obteve-se o seguinte resultado para a extração da tendência:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_trend_pt.jpg}
				
				\caption[\small{Distribuição residual e FFT da tendência.}]{\label{fftAndDistTrend} \small{\textbf{Distribuição residual e FFT do sinal extraído}.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}


\subsection{Sazonalidade}
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{mseComparation_tseasonal_pt.jpg}
				
				\caption[\small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}]{\label{mseSazonal} \small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}Nesse caso observou-se que existe um mínimo local em $T=6$ e um mínimo global em $T=12$. Escolheu se o $T=6$ por ser um múltiplo comum dos dois. Entre as duas análises, a que trouxe melhores resultados foi a que utilizou somente a média móvel. Finalmente obteve-se como resultado da extração os seguintes gráficos:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_seasonal_pt.jpg}
				
				\caption[\small{Distribuição residual e FFT da sazonalidade.}]{\label{fftAndDistSazonal} \small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}}
				
			\end{center}	
		}	
	\end{center}	
\end{figure}

\subsection{Ciclos Senoidais e Resíduo}
\paragraph{}Após o processamento descrito acima, obtém se o sinal $s_{2t}=cs_t+res_t$, o qual tem a seguinte distribuição e FFT.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_residual_pt.jpg}
				
				\caption[\small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}]{\label{fftAndDistCS} \small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}


\paragraph{}Para a extração do resíduo de fato utilizou-se um filtro notch com frequência $w=0.10869$ rad/amostra e $Q=0.01$ removendo então a frequência com maior energia na transformada de Fourier. Obtendo a seguinte distribuição e FFT:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_residualFiltered_pt.jpg}
				
				\caption[\small{Distribuição e FFT após extração da componente de maior energia.}]{\label{fftAndDistFilt} \small{Distribuição e FFT após extração da componente de maior energia.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}Ao final do processo tem-se o seguinte resultado:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{resultPld_tsa_pt.jpg}
				
				\caption[\small{Resultado Final com as componentes separadas utilizando o método descrito acima.}]{\label{resultado_Extracao} \small{Resultado Final com as componentes separadas utilizando o método descrito acima.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Para os outros sinais de entrada a abordagem para a extração do sinal residual foi similar e os gráficos obtidos podem ser vistos no apêndice.

\subsection{Seleção dos atrasos do sinal de saída}
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{autocorrelation_PLD.jpg}
				
				\caption[\small{Autocorrelação do PLD.}]{\label{autoCorrelacaoPLD} \small{Autocorrelação do PLD.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}O gráfico de autocorrelação expressa de forma numérica uma relação linear entre o valor atual e os atrasos. Com isso têm-se os atrasos com maior importância na formação do sinal. Essa informação será utilizada para definir os atrasos utilizados no sinal de entrada.

\subsection{Seleção dos sinais de entrada}
\paragraph{}Os sinais de entrada foram selecionado conforme a seguinte matriz de autocorrelação abaixo:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{corr_plot_pt.jpg}
				
				\caption[\small{Correlação dos dados de entrada.}]{\label{correlacaoDadosEntrada} \small{Correlação dos dados de entrada.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Observou-se alta correlação negativa entre a energia produzida pela hidroelétricas e térmicas. Isso ocorre pelo fato da energia gerada pelas termoelétricas ser a principal substituta para a energia proveniente de usinas térmicas. Sendo assim, decidiu-se então remover a série da energia gerada pelas UTEs de forma a remover a redundância dos dados fornecidos.

\paragraph{}Completar seção do processamento do sinal de entrada
\section{Treinamento das redes neurais}
\paragraph{}Dado que as entradas foram selecionadas e previamente processadas, restou definir a arquitetura da rede neural utilizada. Devido à simplicidade e a boa capacidade de solução de problemas, foi utilizada a rede Perceptron Multicamadas com somente uma camada intermediária. Foi definido para a camada de entrada e a intermediária que a função de ativação utilizada seria a ReLU, dado a velocidade de processamento e os bons resultados obtidos em pesquisas recentes \ref{reluSucesso}. Para a camada de saída, a função de ativação escolhida foi a linear, para que se possa construir a série temporal. O algoritmo de aprendizado utilizado foi o adadelta com learning rate de $\alpha = 0.01$ \cite{adadelta} por conta dos bons resultados obtidos no treinamento e rápida convergência para o estado final.

\paragraph{}O treinamento foi feito utilizando validação cruzada com 8 folds no dataset de treinamento. Assim, como mencionado anteriormente, foram deixados 3 pontos da série temporal para realizar o teste.Para cada fold foram feitas 8 inicializações aleatórias utilizando o método chamado \textit{he uniform}, o qual está descrito em \cite{K_He}. 

\paragraph{}O alpha foi escolhido de forma a fazer com que o gráfico de erro no dataset de teste e no dataset de treino pelo número de neurônios convergisse para todos os folds utilizados na validação cruzada. Foi utilizado o critério de parada antecipada \textit{early stop} para que caso a rede não melhorasse o erro obtido em 25 épocas, o processamento seria então interrompido.

\paragraph{}Apesar das definições acima, ainda há necessidade de definir a quantidade de neurônios na camada intermediária. Foi feito então um treinamento variando o número de neurônios entre 1 e 90 e a partir disso gerou-se um gráfico com o RMSE pelo número de neurônios no conjunto de validação e de teste, conforme a figura abaixo:

\paragraph{}[Inserir a figura do rmse]

\paragraph{}Como forma de avaliação do modelo, foi utilizada a regressão linear sobre o gráfico dos pontos da série original (eixo $X$) pelos pontos do série prevista (eixo $Y$), assim como visto em \ref{fit_linear}. De acordo com essa métrica, o melhor modelo é o que tem o coeficiente angular ($a$) = $1.0$  e offset ($b$) = $0$.



\subsection{Treinamento da rede para obter a saída no mês atual}
\paragraph{}Para o treinamento rede para a saída atual, obteve-se o seguinte gráfico de rmse pelo número de neurônios no conjunto de treinamento:
\paragraph{}[MSE NO CONJUNTO treinamento]

\paragraph{}No conjunto de testes o resultado foi o seguinte:
\paragraph{}[MSE NO CONJUNTO de testes]

\paragraph{}As 5 melhores estruturas de redes ranqueadas pelo critério $\epsilon_3$ definido anteriormente são as seguintes:
\paragraph{}[TABELA Critério $\epsilon_3$]

\paragraph{}E com isso o modelo com 61 neurônios foi escolhido. O treinamento dessa estrutura obteve os seguintes erros pelo número de épocas:

\paragraph{}[GRAFICO CONVERGÊNCIA]

 \paragraph{}E os seguintes resultados foram obtidos:
\paragraph{}[GRÁFICO DO RESÍDUO ORIGINAL X RESÍDUO PREVISTO]
\paragraph{}[GRÁFICO DO SINAL RECONSTRUÍDO]
\paragraph{}Com isso viu-se que a rede está sendo treinada de forma coerente para obter $y(t)$ a partir de $x(t)$. Esse caso também será utilizado como base para as previsões, pois espera-se que o erro para $N$ passos a frente seja sempre maior ou igual ao caso base.

\subsection{Treinamento da rede para obter a saída um mês a frente}
\paragraph{}Seguindo o procedimento previamente determinado, obteve-se os seguintes resultados para a previsão do PLD para 1 mês a frente:

\paragraph{}[TABELA Critério $\epsilon_3$]

\paragraph{}E com isso o modelo com 63 neurônios foi escolhido. O treinamento dessa estrutura obteve os seguintes erros pelo número de épocas:

\paragraph{}[GRAFICO CONVERGÊNCIA]

\paragraph{}E obteve-se os seguintes resultados:
\paragraph{}[GRÁFICO DO RESÍDUO ORIGINAL X RESÍDUO PREVISTO]
\paragraph{}[GRÁFICO DO SINAL RECONSTRUÍDO]

\paragraph{}Para essa previsão, foi treinada uma rede para reduzir o erro de estimação usando como entrada os dados já mencionados anteriormente. Os erros de estimação entre o sinal reconstruído e o original foram utilizados como alvos da rede. Obteve-se então os seguintes resultados:

\paragraph{}[TABELA Critério $\epsilon_3$]

\paragraph{}E com isso o modelo com 58 neurônios foi escolhido. O treinamento dessa estrutura obteve os seguintes erros pelo número de épocas:

\paragraph{}[GRAFICO CONVERGÊNCIA]
\paragraph{}E finalmente obteve-se os seguintes resultados:
\paragraph{}[GRÁFICO DO RESÍDUO ORIGINAL X RESÍDUO PREVISTO]
\paragraph{}[GRÁFICO DO SINAL RECONSTRUÍDO]

\paragraph{}Pelo histograma é possível ver que a rede de correção do erro de estimação diminuiu o erro máximo e mínimo, porém a estrutura sem a correção do erro tem maior concentração de pontos próximos do zero. Sendo assim, espera-se que a saída com a correção de erro erre mais, porém com discrepância pequena, enquanto espera-se que sem a correção de erro o resultado seja melhor na maioria das vezes, podendo correr o risco de errar muito em alguns pontos.

\paragraph{}Cabe a quem for utilizar analisar se compensa mais errar menos na média, porém ter uma chance de errar muito em casos extremos ou errar um pouco mais na média e ter o erro dentre de uma faixa menor.

\subsection{Treinamento da rede para obter a saída para vários meses a frente}
\paragraph{}A rede para vários meses à frente foi treinada de forma similar ao observado anteriormente, porém nesse caso observou-se somente a parte residual e não foi treinada uma rede secundária para corrigir o erro de estimação em cada caso.

\paragraph{}A partir dos resultados, gerou-se o seguinte gráfico que mostra o erro da rede em relação ao sinal original para diferentes números de passos a frente:

[grafico mse pelo número de passos a frente]

\paragraph{}A tabela com os dados utilizados para a seleção do do modelo, os gráficos de convergência e a de cada modelos estão presente nos apêndices A e B respectivamente. Além disso, o gráfico com a comparação do sinal previsto com o resíduo original pode ser visto no apêndice C.


\paragraph{}Assim como o esperado, tanto o erro quanto o desvio padrão aumentam com o número de passos a frente, salvo algumas exceções. Sendo assim, a previsão para muitos passo a frente traz um risco maior para a análise. Cabe a quem for usar mensurar quanto de risco pode ser tolerado baseado nesses gráficos.

\paragraph{}Ainda assim cabe ressaltar que o a análise foi feita somente para a parte residual. Provavelmente ao reconstruir o PLD, os erros ainda devem aumentar, pois serão somados os erros de estimação da tendência, sazonalidade e ciclos senoidais. A estratégia da rede para a correção dos erros pode ser aplicada para cada um dos casos buscando deixar a distribuição do erro mais concentrada em torno do zero.
