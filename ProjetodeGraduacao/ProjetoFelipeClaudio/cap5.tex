\paragraph{}Neste capítulo, são mostrados os resultados obtidos através da aplicação do método descrito no capítulo anterior. Serão detalhados as características dos sinais utilizados assim como os valores dos parâmetros aplicados em cada algoritmo. Alguns resultados obtidos serão expostos no apêndice para facilitar a leitura.

\section{Aquisição dos dados}
\paragraph{}Os dados utilizados e suas respectivas fontes podem ser observados na tabela \ref{table:DadosDeEntrada}. No início do trabalho definiu-se que o foco seria a região sudeste, sendo assim, todos os dados utilizados foram filtrados para a região SE/CO. Os dados provenientes da ONS foram baixados direto do site no formato \textit{Comma Separated Values} - CSV.

\paragraph{} Para facilitar o processamento, foram retiradas todas as colunas que não fossem a data no formato "mês (por extenso) ano". Essas foram então renomeadas para "month" e "value" e o valor do dado referido (ex: MWh produzidos por usinas hidroelétricas no mês), facilitando o desenvolvimento do código. 

\paragraph{}Dado que as regras para o cálculo do PLD variam durante os anos, utilizou-se somente os dados para o período entre 01/2015 e 12/2018, de modo a tentar reduzir ao máximo esse efeito. Sendo assim, o \textit{dataset} possui 48 somente pontos.

\section{Pré-Processamento}
\paragraph{}Antes de poder utilizar o sinais obtidos no treinamento da rede, fez-se necessário selecionar quais sinais seriam realmente fornecidos como entrada para o modelo e quantos atrasos temporais seriam necessários para determinar a saída. Além disso, houve necessidade de extrair a componente residual do PLD e normalizar os dados. Cada um desses tópicos será detalhado nos parágrafos a seguir.

\subsection{Seleção dos sinais de entrada}
\paragraph{}Os sinais de entrada foram selecionado conforme a seguinte matriz de autocorrelação abaixo:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{corr_plot_pt.jpg}
				
				\caption[\small{Correlação dos dados de entrada.}]{\label{correlacaoDadosEntrada} \small{Correlação dos dados de entrada.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Observou-se alta correlação negativa entre a energia produzida pela hidroelétricas e térmicas. Isso ocorre pelo fato da energia gerada pelas termoelétricas ser a principal substituta para a energia proveniente de usinas térmicas. Sendo assim, decidiu-se então remover a série da energia gerada pelas UTEs de forma a remover a redundância dos dados fornecidos.

\subsection{Seleção dos atrasos do sinal de saída}
\paragraph{}O gráfico de autocorrelação expressa de forma numérica uma relação linear entre o valor atual e os atrasos. Com isso, têm-se os atrasos com maior importância na formação do sinal. Foram selecionados os pontos que tinham correlação maior ou próximo do limite do intervalo de 95\% de confiança.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{autocorrelation_PLD.jpg}
				
				\caption[\small{Autocorrelação do PLD.}]{\label{autoCorrelacaoPLD} \small{Autocorrelação do PLD.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Os atrasos obtidos através dessas análises foram replicados para os sinais da entrada, podendo assim definir quantos atrasos seriam necessários para obter informação suficiente para reconstruir a saída. Como conclui-se pelo gráfico que até 20 atrasos temporais são necessários para representar o sinal, o \textit{dataset} de 48 pontos foi reduzido a 28 pontos.

\subsection{Tendência}
\paragraph{}Para a definição do parâmetro $W$, responsável pelo tamanho da janela utilizada no processamento, fez-se um gráfico do MSE pelo tamanho da janela conforme visto na figura a seguir:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{mseComparation_trend_pt.jpg}
				
				\caption[\small{Análise do mse pelo tamanho da janela na extração da tendência.}]{\label{mseTrend} \small{Análise do mse pelo tamanho da janela na extração da tendência.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}Tendo como base o gráfico acima, observou-se que a extração proposta em \ref{maLinFit} obteve os melhores resultados (gráfico na parte superior) e selecionou-se $W=12$. O parâmetro $K$ foi definido como $K=5$ de forma empírica, buscando obter uma transição suave entre a regressão linear e a média móvel. Aplicando esse filtro obteve-se o seguinte resultado para a extração da tendência:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_trend_pt.jpg}
				
				\caption[\small{Histograma e FFT da tendência obtida.}]{\label{fftAndDistTrend} \small{Histograma e FFT da tendência obtida.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}No gráfico acima é possível ver que, assim como esperado, a tendência do sinal possui componentes acentuadas na alta frequência. Já no gráfico de distribuição, observa-se que o preço no sinal está concentrado em 2 patamares, sendo eles: 100-200 R\$/MWh e 300-400 R\$/MWh.

\subsection{Sazonalidade}
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{mseComparation_tseasonal_pt.jpg}
				
				\caption[\small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}]{\label{mseSazonal} \small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}Nesse caso, observou-se que existe um mínimo local em $T=6$ e um mínimo global em $T=12$. Escolheu se o $T=6$ por ser um múltiplo comum dos dois. Entre as duas análises, a que trouxe os melhores resultados foi a que utilizou somente a média móvel (gráfico abaixo). O resultado mostra que os eventos sazonais que influenciam o preço do PLD são de característica anual majoritariamente. Finalmente obteve-se como resultado da extração os seguintes gráficos:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_seasonal_pt.jpg}
				
				\caption[\small{Histograma e FFT da sazonalidade obtida.}]{\label{fftAndDistSazonal} \small{Histograma e FFT da sazonalidade obtida.}}
				
			\end{center}	
		}	
	\end{center}	
\end{figure}

\paragraph{}No gráfico acima é possível ver que a distribuição do erro já está centrada perto de um ponto e que este está próximo de zero. No gráfico da FFT, observa-se que diferentemente da FFT vista extração do ciclo senoidal, existe um pico por volta de 0.18 rad/amostra. Isso era é esperado, uma vez que a parte de baixa frequência foi removida na extração anterior. 

\subsection{Ciclos Senoidais e Resíduo}
\paragraph{}Após o processamento descrito acima, obtém sinal $s_{2t}=cs_t+res_t$, o qual tem a seguinte distribuição e FFT.

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_residual_pt.jpg}
				
				\caption[\small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}]{\label{fftAndDistCS} \small{Análise do mse pelo tamanho da janela na extração da sazonalidade.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}


\paragraph{}A distribuição observada está centrada em $0$ R\$/MWh e, dentre os picos observados na FFT, o com maior módulo é o que está presente na frequência $w=0.10869$ rad/amostra. Sendo assim, a extração do resíduo de foi feita com um filtro Notch na maior frequência observada e $Q=0.01$ removendo então a frequência com maior energia na transformada de Fourier. Após este processamento, obteve-se os seguintes resultados:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{fftAndDistribution_residualFiltered_pt.jpg}
				
				\caption[\small{Distribuição e FFT após extração da componente de maior energia.}]{\label{fftAndDistFilt} \small{Distribuição e FFT após extração da componente de maior energia.}}
				
			\end{center}
			
		}	
	\end{center}	
\end{figure}

\paragraph{}É possível observar que a distribuição continuou centrada em torno de $0$ R\$/MWh, porém com um formato diferente. Além disso, a FFT mostra que as magnitudes estão espalhadas por todo o espectro ao invés de concentradas em poucas frequências. Isso atende à expectativa de que o ruído obtido ao final do processamento deveria estar distribuído ter componentes de frequência com intensidades similares por todo espectro.

\paragraph{}Ao final do processo, os seguintes resultados foram obtidos:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{resultPld_tsa_pt.jpg}
				
				\caption[\small{Resultado Final com as componentes separadas utilizando o método descrito acima.}]{\label{resultado_Extracao} \small{Resultado Final com as componentes separadas utilizando o método descrito acima.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\section{Treinamento das redes neurais}
\paragraph{}O treinamento foi feito utilizando validação cruzada com 8 folds no dataset de treinamento. Foram deixados 3 pontos da série temporal para realizar o teste. Para cada fold foram feitas 3 inicializações aleatórias utilizando o método chamado \textit{he uniform}, o qual está descrito em \cite{K_He}. Os 3 últimos foram separados para teste e os outros 25 foram utilizados na validação cruzada. Após a extração residual, os dados são normalizados para facilitar a convergência do treinamento, assim como mostrado em na seção \ref{treinamento_mlp}. 

\paragraph{} O algoritmo de aprendizado utilizado foi o AdaDelta com learning rate de $\alpha = 0.01$ \cite{adadelta} por conta dos bons resultados obtidos no treinamento e rápida convergência para o estado final.  Foi utilizado o critério de parada antecipada \textit{early stop} para que caso a rede não melhorasse o erro obtido em 25 épocas, o processamento seria então interrompido.

\paragraph{} Foram realizados treinamento variando o número de neurônios entre 1 e 90, buscando obter o número de neurônios ideal na camada intermediária. A partir disso, gerou-se um gráfico com o RMSE pelo número de neurônios no conjunto de validação e de teste.

\subsection{Treinamento da rede para obter a saída no mês atual}
\paragraph{}Para o treinamento rede para a saída atual, obteve-se o seguinte gráfico de RMSE pelo número de neurônios no conjunto de treinamento:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{rmse_val_set_t0.jpg}
				
				\caption[\small{RMSE pelo número de neurônios no conjunto de validação.}]{\label{mseValT0} \small{RMSE pelo número de neurônios no conjunto de validação.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}


\paragraph{}No conjunto de testes o resultado foi o seguinte:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{rmse_test_set_t0.jpg}
				
				\caption[\small{RMSE pelo número de neurônios no conjunto de teste.}]{\label{mseTestT0} \small{RMSE pelo número de neurônios no conjunto de teste.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Esperava-se que o gráfico do RMSE pelo número de neurônios na camada intermediária fosse decrescente, mas o resultado obtido oscilou em torno de um valor de RMSE. Isso pode ser uma das consequências da pouca quantidade de dados tanto para teste quanto para a validação. Redes neurais geralmente necessitam de grande conjuntos de dados para que se possa definir os pesos das conexões sinápticas de forma correta. Sendo assim, esse gráfico não foi suficiente para determinar qual estrutura seria utilizada para realizar as previsões. Para poder ranquear as estruturas e, então, escolher a utilizada nas previsões, fez a seguinte tabela. Os dados mostrado a seguir contém as 5 melhores estruturas de redes ranqueadas pelo critério $\epsilon_3$ definido anteriormente:
\begin{table}[H]
	
	\begin{center}	
		\caption{Resultados obtidos com as redes no dataset de validação.}		
		\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline \label{table:tabelaT0}
			 
			\textbf{\#neurônios} & \textbf{RMSE} & \textbf{STD} & \textbf{$a$ (média)} & \textbf{$\epsilon_1$} & \textbf{$b$ (média)} & \textbf{$\epsilon_2$} & \textbf{$\epsilon_3$}\\ \hline \vspace{-1.0mm}61 &64,435 & 61,180 &  0,998 & 0,008 & -0,007 & 0,175 & 0,184 \\ \hline
			38 & 66,896 & 63,894 & 1,005 & 0,019 & -0,003 & 0,175 & 0,194 \\ \hline
			97 & 63,509 & 61,957 & 1,000 & 0,001 & 0,046 & 0,224 & 0,225 \\ \hline
			77 & 56,788 & 54,954 & 1,003 & 0,010 & 0,044 & 0,224 & 0,234 \\ \hline
			92 & 55,370 & 53,135 & 0,983 & 0,063 & 0,009 & 0,224 & 0,287 \\ \hline
		\end{tabular}	
	\end{center} 
\end{table}

\paragraph{}E com isso o modelo com 61 neurônios foi escolhido. O treinamento dessa estrutura obteve os seguintes erros pelo número de épocas e por folds:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{convergence_t0.jpg}
				
				\caption[\small{Erro pelo número de época e por fold.}]{\label{convT0} \small{Erro pelo número de época e por fold.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}E os seguintes resultados foram obtidos:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{sinal_completo_t0.jpg}
				
				\caption[\small{Sinal completo.}]{\label{completoT0} \small{Sinal completo.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Os 3 últimos pontos são do conjunto de dados de teste. Observa-se que a rede não conseguiu prevê-los tão bem quanto os pontos do conjunto de treinamento, assim como esperado.

\paragraph{}Dado a pouca quantidade de dados, a rede não obteve o comportamento esperado nos treinamentos, porém o resultado obtido mostrou que a mesma conseguiu mapear bem a entrada na saída. Sendo assim, viu-se que a rede está sendo treinada de forma coerente para obter $y(t)$ a partir de $x(t)$. Esse caso também será utilizado como base para as previsões, pois espera-se que o erro para $N$ passos a frente seja sempre maior ou igual ao caso base.

\subsection{Treinamento da rede para obter a saída um mês a frente}
\paragraph{}Seguindo o procedimento previamente determinado, obteve-se os seguintes resultados para a previsão do PLD para 1 mês a frente:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{rmse_val_set_t1.jpg}
				
				\caption[\small{RMSE pelo número de neurônios no conjunto de validação.}]{\label{rmseValT1} \small{RMSE pelo número de neurônios no conjunto de validação.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}


\paragraph{}No conjunto de teste o resultado foi o seguinte:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{rmse_test_set_t1.jpg}
				
				\caption[\small{RMSE pelo número de neurônios no conjunto de teste.}]{\label{rmseTestT1} \small{RMSE pelo número de neurônios no conjunto de teste.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\begin{table}[H]
	
	\begin{center}
		\caption{Resultados obtidos com as redes no dataset de validação.}	
		\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline \label{table:tabelaT1}
			
			\textbf{\#neurônios} & \textbf{RMSE} & \textbf{STD} & \textbf{$a$ (média)} & \textbf{$\epsilon_1$} & \textbf{$b$ (média)} & \textbf{$\epsilon_2$} & \textbf{$\epsilon_3$}\\ \hline \vspace{-1.0mm}63 & 82,911 & 69,521 & 0,993 & 0,002 & 0,005 & 0,003 & 0,004 \\ \hline
			71 & 88,327 & 74,076 & 0,985 & 0,004 & -0,027 & 0,014 & 0,018 \\ \hline
			25 & 93,041 & 73,840 & 0,966 & 0,008 & 0,020 & 0,010 & 0,018 \\ \hline
			50 & 103,137 & 93,552 & 0,927 & 0,018 & 0,032 & 0,016 & 0,034 \\ \hline
			51 & 94,937 & 81,015 & 0,860 & 0,034 & 0,000 & 0,000 & 0,034 \\ \hline
		\end{tabular}
	\end{center} 
\end{table}
\paragraph{}E com isso o modelo com 63 neurônios foi escolhido. O treinamento dessa estrutura obteve os seguintes erros pelo número de épocas:


\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{convergence_t1.jpg}
				
				\caption[\small{Erro pelo número de épocas e por fold.}]{\label{convT1} \small{Erro pelo número de épocas e por fold.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}E obteve-se os seguintes resultados:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{sinal_completo_t1.jpg}
				
				\caption[\small{Sinal completo.}]{\label{completoT1} \small{Sinal completo.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Para essa previsão, foi treinada uma rede para reduzir o erro de estimação usando como entrada os dados já mencionados anteriormente. Os erros de estimação entre o sinal reconstruído e o original foram utilizados como alvos da rede. Obteve-se então os seguintes resultados:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{rmse_val_set_t1_error.jpg}
				
				\caption[\small{RMSE pelo número de neurônios no conjunto de validação.}]{\label{mseValT1Error} \small{RMSE pelo número de neurônios no conjunto de validação.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}


\paragraph{}No conjunto de teste o resultado foi o seguinte:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{rmse_test_set_t1_error.jpg}
				
				\caption[\small{RMSE pelo número de neurônios no conjunto de teste.}]{\label{mseTestT1Error} \small{RMSE pelo número de neurônios no conjunto de teste.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\begin{table}[H]
	
	\begin{center}
		\caption{Resultados obtidos com as redes no dataset de validação.}			
		\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline \label{table:tabelaT1Erro}
			
			\textbf{\#neurônios} & \textbf{RMSE} & \textbf{STD} & \textbf{$a$ (média)} & \textbf{$\epsilon_1$} & \textbf{$b$ (média)} & \textbf{$\epsilon_2$} & \textbf{$\epsilon_3$}\\ \hline \vspace{-1.0mm}90 & 126,678 & 101,233 & 1,029 & 0,001 & -0,001 & 0,000 & 0,001  \\ \hline
			14 & 130,352 & 98,738 & 0,973 & 0,001 & -0,002 & 0,000 & 0,001  \\ \hline
			46 & 137,971 & 99,784 & 1,017 & 0,001 & -0,017 & 0,001 & 0,002  \\ \hline
			76 & 136,014 & 105,032 & 0,982 & 0,001 & 0,057 & 0,003 & 0,004  \\ \hline
			60 & 123,420 & 98,844 & 1,070 & 0,002 & -0,031 & 0,002 & 0,004  \\ \hline
		\end{tabular}
	\end{center} 
\end{table}

\paragraph{}E com isso o modelo com 90 neurônios foi escolhido. O treinamento dessa estrutura obteve os seguintes erros pelo número de épocas:


\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{convergence_t1_error.jpg}
				
				\caption[\small{Erro pelo número de épocas e por fold.}]{\label{convT1erro} \small{Erro pelo número de épocas e por fold.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}E finalmente obteve-se os seguintes resultados:
\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{sinal_completo_t1_error.jpg}
				
				\caption[\small{Sinal completo.}]{\label{completoT1Error} \small{Sinal completo.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{original_pred_rede_erro_hist.jpg}
				
				\caption[\small{Histograma de previsão sem e com a correção de erro.}]{\label{histErro} \small{Histograma de previsão sem e com a correção de erro.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}Pelo histograma é possível ver que a rede de correção do erro de estimação diminuiu o erro máximo e mínimo, porém a estrutura sem a correção do erro tem maior concentração de pontos próximos do zero. Sendo assim, espera-se que a saída com a correção de erro erre mais, porém com discrepância menor, enquanto espera-se que sem a correção de erro o resultado seja melhor na maioria das vezes, podendo correr o risco de errar muito em alguns pontos.

\paragraph{}Cabe a quem for utilizar analisar se compensa mais errar menos na média, porém ter uma chance de errar muito em casos extremos ou errar um pouco mais na média e ter o erro dentre de uma faixa menor.

\subsection{Treinamento da rede para obter a saída para vários meses a frente}
\paragraph{}A rede para vários meses à frente foi treinada de forma similar ao observado anteriormente, porém nesse caso observou-se somente a parte residual e não foi treinada uma rede secundária para corrigir o erro de estimação em cada caso.

\paragraph{}A partir dos resultados, gerou-se o seguinte gráfico que mostra o erro da rede em relação ao sinal original para diferentes números de passos a frente:

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{mean_std_test_best_prev.jpg}
				
				\caption[\small{Erro no sinal residual pelo número de passos no conjunto de dados de teste.}]{\label{rmsePassosTeste} \small{Erro no sinal residual pelo número de passos no conjunto de dados de teste.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\begin{figure}[H]
	\begin{center}
		{
			\begin{center}
				
				\includegraphics[width=\textwidth]{mean_std_comp_best_prev.jpg}
				
				\caption[\small{Erro no sinal residual pelo número de passos no conjunto de dados completo.}]{\label{rmsePassosVomp} \small{Erro no sinal residual pelo número de passos no conjunto de dados de completo.}}
				
			\end{center}
		}	
	\end{center}	
\end{figure}

\paragraph{}A tabela com os dados utilizados na seleção de cada modelo, o gráfico de convergência e os resultados obtidos  estão presente no apêndice A.

\paragraph{}Assim como o esperado, tanto o erro quanto o desvio padrão aumentam com o número de passos a frente, salvo algumas exceções. Sendo assim, a previsão para muitos passo a frente traz um risco maior para a análise. Cabe a quem for usar mensurar quanto de risco pode ser tolerado baseado nesses gráficos.

\paragraph{}Ainda assim cabe ressaltar que o a análise foi feita somente para a parte residual. Provavelmente ao reconstruir o PLD, os erros ainda devem aumentar, pois serão somados os erros de estimação da tendência, sazonalidade e ciclos senoidais. A estratégia da rede para a correção dos erros pode ser aplicada para cada um dos casos buscando deixar a distribuição do erro mais concentrada em torno do zero.
