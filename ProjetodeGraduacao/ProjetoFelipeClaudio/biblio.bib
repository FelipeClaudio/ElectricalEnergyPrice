@MASTERSTHESIS{
	AlteracaoModeloComercializacao,
	AUTHOR = "Edimilson Ferreira da Silva",
	TITLE = "Principais Condicionantes das alterações no modelo de comercialização",
	SCHOOL = "Escola Politécnica da Universidade de São Paulo",
	YEAR = "2008",
}
@MISC{
	EPE,
	AUTHOR = "EPE",
	TITLE = "Empresa de Pesquisa Energética",
	HOWPUBLISHED = "http://www.epe.gov.br/pt/abcdenergia/matriz-energetica-e-eletrica",
  	YEAR = "2018",
  	NOTE = "(Acesso em 26 Janeiro 2019)",
}
@MISC{
	ONS,
	AUTHOR = "ONS",
	TITLE = "Operador Nacional do Sistema Elétrico",
	HOWPUBLISHED = "http://ons.org.br/",
	YEAR = "2019",
	NOTE = "(Acesso em 27 Janeiro 2019)"
}
@MISC{
	CCEE,
	AUTHOR = "CCEE",
	TITLE = "Câmara de Comercialização de Energia Elétrica",
	HOWPUBLISHED = "https://www.ccee.org.br/",
	YEAR = "2019",
	NOTE = "(Acesso em 31 Janeiro 2019)",
}

@MISC{
	CRISE_2014,
	AUTHOR = "Energia Inteligente UFJF",
	TITLE = "Especial: A crise energética brasileira",
	HOWPUBLISHED = "http://energiainteligenteufjf.com/especial/especial-a-crise-energetica-brasileira/",
	YEAR = "2019",
	NOTE = "(Acesso em 26 Fevereiro 2019)",
}
@MISC{
	MANUAIS,
	AUTHOR = "CEPEL",
	TITLE = "Documentação Técnica das metodologias e modelos de otimização energética do CEPEL",
	HOWPUBLISHED = "http://www.cepel.br/sala-de-imprensa/noticias/menu/noticias/documentacao-tecnica-das-metodologias-e-modelos-de-otimizacao-energetica-do-cepel.htm",
	YEAR = "2019",
	NOTE = "(Acesso em 26 Fevereiro 2019)",
}
@MISC{
	RES_NORMA_482,
	AUTHOR = "ANEEL",
	TITLE = "Resolução normativa nº 482, de 17 de abril de 2012",
	HOWPUBLISHED = "http://www2.aneel.gov.br/cedoc/ren2012482.pdf",
	YEAR = "2019",
	NOTE = "(Acesso em 26 Fevereiro 2019)",
}
@MISC{
	ANEEL,
	AUTHOR = "ANEEL",
	TITLE = "Bem-vindo à ANEEL!",
	HOWPUBLISHED = "https://www.aneel.gov.br/a-aneel",
	YEAR = "2020",
	NOTE = "(Acesso em 29 Fevereiro 2020)",
}
@MISC{
	DECRETO_2003,
	AUTHOR = "Subchefia para Assuntos Jurídicos",
	TITLE = "DECRETO Nº 2.003, DE 10 DE SETEMBRO DE 1996",
	HOWPUBLISHED = "http://www.planalto.gov.br/ccivil\_03/decreto/D2003.html",
	YEAR = "2020",
	NOTE = "(Acesso em 29 Fevereiro 2020)",
}
@PHDTHESIS{
	EvolucaoSetorEletrico,
	AUTHOR = "Bruno Gonçalves Da Silva",
	TITLE = "Evolução do setor elétrico brasileiro no contexto econômico nacional: Uma análise histórica e econométrica de longo prazo",
	SCHOOL = "Universidade de São Paulo -
	Programa de pós-graduação em energia EP-FEA-IEE-IF",
	YEAR = "2011",
}
@PHDTHESIS{
	PrevisaoMultiPassos,
	AUTHOR = "José Carlos Reston Filho",
	TITLE = "Previsão multi-passo a frente do preço de energia elétrica de curto prazo no mercado brasileiro",
	SCHOOL = "Universidade Federal do Pará - Instituto de Tecnologia, programa de pós-graduação em engenharia elétrica",
	YEAR = "2014"
}
@MISC{
	PrevisaoPrecoFuturoACL,
	AUTHOR = "Mateus Alves Cavaliere",
	TITLE = "Previsão de preços futuros de energia eleétrica no ambiente de contratação livre - uma abordagem de equilíbrio de mercado sob incertezas",
	SCHOOL = "Universidade Federal do Rio de Janeiro",
	YEAR = "2017",
}
@MISC{
	SmartGrid,
	AUTHOR = "Eduardo Pacheco Bueno Muniz Barretto",
	TITLE = "Smart grid: Eficiência energética e a geração distribuida a partir das redes inteligentes",
	SCHOOL = "Universidade Federal do Rio de Janeiro",
	YEAR = "2018",
}
@MISC{
	TCC_PLD,
	AUTHOR = "Alan Patrik Souza Silva",
	TITLE = "Previsão do preço de liquidação das diferenças por meio de redes neurais artificiais",
	SCHOOL = "Universidade Federal de Ouro Preto",
	YEAR = "2018",
}
@ARTICLE{
	PRECO_SPOT,
	AUTHOR = "Nivalde José de Castro and André Luis da Silva Leite",
	TITLE = "Preço spot de eletricidade: teoria e evidências do caso brasileiro",
	JOURNAL = "IV Encontro de Enconomia Catarinense, 2010, Criciúma",
	YEAR = "2010",
}
@misc{
	AdaDelta,
	title={ADADELTA: An Adaptive Learning Rate Method},
	author={Matthew D. Zeiler},
	year={2012},
	eprint={1212.5701},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}
@MISC{
	birthNY,
	AUTHOR = "Newton (1988)",
	TITLE = "Monthly New York City births: unknown scale. Jan 1946 ? Dec 1959",
	HOWPUBLISHED = "https://datamarket.com/data/set/22nv/monthly-new-york-city-births-unknown-scale-jan-1946-dec-1959\#!ds=22nv\&display=line",
	YEAR = "1988",
	NOTE = "(Acesso em 9 de Abril 2019)",
}
@MISC{
	shampooSales,
	AUTHOR = "Makridakis, Wheelwright and Hyndman",
	TITLE = "Sales of shampoo over a three year period",
	HOWPUBLISHED = "https://datamarket.com/data/set/22r0/sales-of-shampoo-over-a-three-year-period\#!ds=22r0\&display=line",
	YEAR = "1998",
	NOTE = "(Acesso em 9 de Abril 2019)",
}
@BOOK{
	sTemp,
	TITLE="Análise de Séries Temporais",
	AUTHOR="Ricardo Sandes Ehlers",
	YEAR={2009}
}
@BOOK{
	apostilaCaloba,
	TITLE="Introdução ao Uso de Redes Neurais na Modelagem de
	Sistemas Dinâmicos e Séries Temporais.",
	AUTHOR="Luiz Pereira Calôba",
	HOWPUBLISHED="XIV Congresso Brasileiro de Automática, Natal",
	YEAR={2002},
}
@BOOK{
	introSP,
	TITLE="Introduction to Signal Processing",
	AUTHOR="Sophocle J. Orfanidis",
	HOWPUBLISHED="https://www.ece.rutgers.edu/~orfanidi/intro2sp/",
	YEAR={2002},
}
@MISC{
	tccDanilo,
	AUTHOR = "Danilo Filippo Reiszel Pereira",
	TITLE = "Aprendizado de máquina e aprendizado profundo para apoio à decisão no mercado financeiro",
	SCHOOL = "Univeridade Federal de do Rio de Janeiro",
	YEAR = "2018",
}

@MISC{
	neuronio,
	TITLE = "O que é neurônio?",
	AUTHOR = "Brasil Escola",
	HOWPUBLISHED = "https://brasilescola.uol.com.br/o-que-e/biologia/o-que-e-neuronio.htm",
	YEAR= "2019"	
}

@MISC{
	neuronio_artificial,
	TITLE = "Redes Neurais Artificiais",
	AUTHOR = "Anderson Vinicius",
	HOWPUBLISHED = "https://medium.com/@avinicius.adorno/redes-neurais-artificiais-418a34ea1a39",
	YEAR= "2017"
}

@MISC{
	funcoes_ativacao,
	TITLE = "Redes Neurais Artificiais",
	AUTHOR = "Sagar Sharma",
	HOWPUBLISHED = "https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6",
	YEAR= "2017"
}

@MISC{
	tanh,
	TITLE = "tanh-activation-function",
	AUTHOR = "Saugat Bhattarai",
	HOWPUBLISHED = "https://saugatbhattarai.com.np/what-is-activation-functions-in-neural-network-nn/logistic-sigmoid-unipolar-tanh-bipolar/",
	YEAR= "2018"
}

@MISC{
	relu,
	TITLE = "ReLU : Not a Differentiable Function: Why used in Gradient Based Optimization? and Other Generalizations of ReLU.",
	AUTHOR = "Kanchan Sarkar",
	HOWPUBLISHED = "https://medium.com/@kanchansarkar/relu-not-a-differentiable-function-why-used-in-gradient-based-optimization-7fef3a4cece",
	YEAR= "2018"
}

@MISC{
	grad_desc,
	TITLE = "Gradient Descent Algorithm and Its Variants",
	AUTHOR = "Imad Dabbura",
	HOWPUBLISHED = "https://towardsdatascience.com/gradient-descent-algorithm-and-its-variants-10f652806a3",
	YEAR= "2017"
}

@MISC{
	mlp,
	TITLE = "Rede Neural Perceptron Multicamadas",
	AUTHOR = "Sandro Moreira",
	HOWPUBLISHED = "https://medium.com/ensina-ai/rede-neural-perceptron-multicamadas-f9de8471f1a9",
	YEAR= "2018"
}

@book{
	ivan_nunes,
	title   = {Redes neurais artificiais para engenharia e ciências aplicadas},
	author = {Silva, Ivan Nunes da and Spatti, Danilo Hernane and Flauzino, Rogério Andrade},
	year = {2010},
	publisher = {Artliber Editora}
}

@MISC{
	validacao_cruzada,
	TITLE = "Bias vs. Variância (Parte 2) ",
	AUTHOR = "
	Eric Couto ",
	HOWPUBLISHED = "https://ericcouto.wordpress.com/2013/07/18/bias-vs-variancia-parte-2/",
	YEAR= "2013"
}

@book{
	Gurney,
	author = {Gurney, Kevin},
	title = {An  Introduction to Neural Networks},
	year = {1997},
	isbn = {1857286731},
	publisher = {Taylor \& Francis, Inc.},
	address = {Bristol, PA, USA},
} 

@book{
	Bishop,
	author = {Bishop, Christopher M.},
	title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
	year = {2006},
	isbn = {0387310738},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg},
} 

@article{
	K_He,
	author    = {Kaiming He and
	Xiangyu Zhang and
	Shaoqing Ren and
	Jian Sun},
	title     = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on
	ImageNet Classification},
	journal   = {CoRR},
	volume    = {abs/1502.01852},
	year      = {2015},
	url       = {http://arxiv.org/abs/1502.01852},
	archivePrefix = {arXiv},
	eprint    = {1502.01852},
	timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/HeZR015},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{
	backprop,
	author={ {Hecht-Nielsen}},
	booktitle={International 1989 Joint Conference on Neural Networks},
	title={Theory of the backpropagation neural network},
	year={1989},
	volume={},
	number={},
	pages={593-605 vol.1},
	keywords={biocybernetics;neural nets;neurophysiology;parallel architectures;physiological models;backpropagation neural network;architecture;performance measurement;function approximation;neurophysiological model;mammalian brain;corticocortical learning;cerebral cortex;Cybernetics;Neural networks;Nervous system;Parallel architectures;Biological system modeling},
	doi={10.1109/IJCNN.1989.118638},
	ISSN={},
	month={},
}

@article{
	mlp_atmosfera,
	added-at = {2011-01-24T09:52:55.000+0100},
	author = {Gardner, MW and Dorling, SR},
	biburl = {https://www.bibsonomy.org/bibtex/25bade65c44df9ccc9c07aca504fe3d9c/a.guidali},
	date-added = {2010-05-25 17:01:14 +0200},
	date-modified = {2010-05-25 17:01:14 +0200},
	interhash = {af06a16cc53134ae970625bd736bf9d8},
	intrahash = {5bade65c44df9ccc9c07aca504fe3d9c},
	journal = {Atmospheric Environment},
	keywords = {imported},
	number = {14-15},
	pages = {2627--2636},
	publisher = {Elsevier},
	timestamp = {2011-01-24T09:52:56.000+0100},
	title = {{Artificial neural networks (the multilayer perceptron)---A review of applications in the atmospheric sciences}},
	volume = 32,
	year = 1998
}
@article{
	deep_learning_relu,
	author    = {Abien Fred Agarap},
	title     = {Deep Learning using Rectified Linear Units (ReLU)},
	journal   = {CoRR},
	volume    = {abs/1803.08375},
	year      = {2018},
	url       = {http://arxiv.org/abs/1803.08375},
	archivePrefix = {arXiv},
	eprint    = {1803.08375},
	timestamp = {Mon, 13 Aug 2018 16:47:13 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1803-08375},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
	relu_recomender,
	author = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan and Jain, Vihan and Liu, Xiaobing and Shah, Hemal},
	title = {Wide \& Deep Learning for Recommender Systems},
	booktitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems},
	series = {DLRS 2016},
	year = {2016},
	isbn = {978-1-4503-4795-2},
	location = {Boston, MA, USA},
	pages = {7--10},
	numpages = {4},
	url = {http://doi.acm.org/10.1145/2988450.2988454},
	doi = {10.1145/2988450.2988454},
	acmid = {2988454},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {Recommender Systems, Wide \& Deep Learning},
} 



@article{
	deep_learning_relu2,
	author    = {Yichuan Tang},
	title     = {Deep Learning using Support Vector Machines},
	journal   = {CoRR},
	volume    = {abs/1306.0239},
	year      = {2013},
	url       = {http://arxiv.org/abs/1306.0239},
	archivePrefix = {arXiv},
	eprint    = {1306.0239},
	timestamp = {Mon, 13 Aug 2018 16:49:05 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/Tang13},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE {
	mlp_book,
	author = {T. H. Hildebrandt and A. Dingle},
	journal = {Computer},
	title = {Improving C++ Performance Using Temporaries},
	year = {1998},
	volume = {29},
	number = {03},
	issn = {0018-9162},
	pages = {31-41},
	keywords = {},
	doi = {10.1109/2.660188},
	publisher = {IEEE Computer Society},
	address = {Los Alamitos, CA, USA},
	month = {mar}
}

@article{
	deep_learning1,
	title = "Deep learning in neural networks: An overview",
	journal = "Neural Networks",
	volume = "61",
	pages = "85 - 117",
	year = "2015",
	issn = "0893-6080",
	doi = "https://doi.org/10.1016/j.neunet.2014.09.003",
	url = "http://www.sciencedirect.com/science/article/pii/S0893608014002135",
	author = "Jürgen Schmidhuber",
	keywords = "Deep learning, Supervised learning, Unsupervised learning, Reinforcement learning, Evolutionary computation",
	abstract = "In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks."
}
@article{
	deep_learning_book,

	url = {http://dx.doi.org/10.1561/2000000039},

	year = {2014},

	volume = {7},

	journal = {Foundations and Trends® in Signal Processing},

	title = {Deep Learning: Methods and Applications},

	doi = {10.1561/2000000039},

	issn = {1932-8346},

	number = {3?4},

	pages = {197-387},

	author = {Li Deng and Dong Yu}

},
@Article{
	microsoft_dl,
	author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Kingsbury, Brian and Sainath, Tara},
	title = {Deep Neural Networks for Acoustic Modeling in Speech Recognition},
	year = {2012},
	month = {November},
	abstract = {Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.},
	url = {https://www.microsoft.com/en-us/research/publication/deep-neural-networks-for-acoustic-modeling-in-speech-recognition/},
	pages = {82-97},
	journal = {IEEE Signal Processing Magazine},
	volume = {29},
	edition = {IEEE Signal Processing Magazine},
}
@article{
	yam,
	title = "A weight initialization method for improving training speed in feedforward neural network",
	journal = "Neurocomputing",
	volume = "30",
	number = "1",
	pages = "219 - 232",
	year = "2000",
	issn = "0925-2312",
	doi = "https://doi.org/10.1016/S0925-2312(99)00127-7",
	url = "http://www.sciencedirect.com/science/article/pii/S0925231299001277",
	author = "Jim Y.F. Yam and Tommy W.S. Chow",
	keywords = "Initial weights determination, Feedforward neural networks, Backpropagation, Linear least squares, Cauchy inequality",
	abstract = "An algorithm for determining the optimal initial weights of feedforward neural networks based on the Cauchy's inequality and a linear algebraic method is developed. The algorithm is computational efficient. The proposed method ensures that the outputs of neurons are in the active region and increases the rate of convergence. With the optimal initial weights determined, the initial error is substantially smaller and the number of iterations required to achieve the error criterion is significantly reduced. Extensive tests were performed to compare the proposed algorithm with other algorithms. In the case of the sunspots prediction, the number of iterations required for the network initialized with the proposed method was only 3.03% of those started with the next best weight initialization algorithm."
}

@article{
	ryanhsiao,
	title = "Partial least-squares algorithm for weights initialization of backpropagation network",
	journal = "Neurocomputing",
	volume = "50",
	pages = "237 - 247",
	year = "2003",
	issn = "0925-2312",
	doi = "https://doi.org/10.1016/S0925-2312(01)00708-1",
	url = "http://www.sciencedirect.com/science/article/pii/S0925231201007081",
	author = "Tzu-Chien Ryan Hsiao and Chii-Wann Lin and Huihua Kenny Chiang",
	keywords = "Weights initialization, Backpropagation network, Partial least-squares, Feedforward neural networks",
	abstract = "This paper proposes a hybrid scheme to set the weights initialization and the optimal number of hidden nodes of the backpropagation network (BPN) by applying the loading weights and factor numbers of the partial least-squares (PLS) algorithm. The joint PLS and BPN method (PLSBPN) starts with a small residual error, modifies the latent weight matrices, and obtains a near-global minimum in the calibration phase. Performances of the BPN, PLS, and PLSBPN were compared for the near infrared spectroscopic analysis of glucose concentrations in aqueous matrices. The results showed that the PLSBPN had the smallest root mean square error. The PLSBPN approach significantly solves some conventional problems of the BPN method by providing the good initial weights, reducing the calibration time, obtaining an optimal solution, and easily determining the number of hidden nodes."
}

@ARTICLE{
	data_overfit,
	author = {{Russo}, Daniel and {Zou}, James},
	title = "{How much does your data exploration overfit? Controlling bias via information usage}",
	journal = {arXiv e-prints},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	year = "2015",
	month = "Nov",
	eid = {arXiv:1511.05219},
	pages = {arXiv:1511.05219},
	archivePrefix = {arXiv},
	eprint = {1511.05219},
	primaryClass = {stat.ML},
	adsurl = {https://ui.adsabs.harvard.edu/abs/2015arXiv151105219R},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{
	crossValidation,
	author = {{Arlot}, Sylvain and {Celisse}, Alain},
	title = "{A survey of cross-validation procedures for model selection}",
	journal = {arXiv e-prints},
	keywords = {Mathematics - Statistics Theory, Statistics - Applications, Statistics - Methodology, Statistics - Machine Learning, 62G08, 62G05, 62G09},
	year = "2009",
	month = "Jul",
	eid = {arXiv:0907.4728},
	pages = {arXiv:0907.4728},
	archivePrefix = {arXiv},
	eprint = {0907.4728},
	primaryClass = {math.ST},
	adsurl = {https://ui.adsabs.harvard.edu/abs/2009arXiv0907.4728A},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@MASTERSTHESIS{
	RNA_DIRETA_E_RECORRENTE,
	AUTHOR = "Flaviano Ramos Pereira Junior",
	TITLE = "Redes neurais diretas e recorrentes na previsão do preço de energia elétrica de curto prazo no mercado brasileiro",
	SCHOOL = "Universidade Federal do Pará",
	YEAR = "2016",
}

@MASTERSTHESIS{
	RNA_PRECO_SPOT,
	AUTHOR = "Alcantaro Lemes Rodrigues",
	TITLE = "Redes neurais artificiais aplicadas na previsão de preços do mercado spot de energia elétrica",
	SCHOOL = "Universidade de São Paulo",
	YEAR = "2009",
}

@MASTERSTHESIS{
	GARCH_PLD,
	AUTHOR = "Antônio José Sobrinho de Sousa",
	TITLE = "Análise e Previsão da Volatilidade do Preçode Liquidação das Diferençasno Mercado Brasileiro Utilizando o Modelo GARCH",
	SCHOOL = "Universidade Federal da Bahia",
	YEAR = "2013",
}
@MISC{
	TCC_FABIANE,
	AUTHOR = "Fabiane Barbosa do Nascimento",
	TITLE = "Redes Neurais Artificiais Aplicadas à Predição do Preço De Liquidação das Diferenças no Mercado De Energia",
	SCHOOL = "Universidade Federal de Juiz de Fora",
	YEAR = "2017",
}
@ARTICLE{
	PSF_forecast,
	author={F. {Martinez Alvarez} and A. {Troncoso} and J. C. {Riquelme} and J. S. {Aguilar Ruiz}},
	journal={IEEE Transactions on Knowledge and Data Engineering},
	title={Energy Time Series Forecasting Based on Pattern Sequence Similarity},
	year={2011},
	volume={23},
	number={8},
	pages={1230-1243},
	keywords={pattern clustering;time series;energy time series forecasting;pattern sequence similarity;clustering techniques;data point prediction;Electrostatic discharge;Silicon;Time series;forecasting;patterns.},
	doi={10.1109/TKDE.2010.227},
	ISSN={1041-4347},
	month={Aug},
}
@ARTICLE{
	simple_forecast,
	author={C. P. {Rodriguez} and G. J. {Anders}},
	journal={IEEE Transactions on Power Systems},
	title={Energy price forecasting in the Ontario competitive power system market},
	year={2004},
	volume={19},
	number={1},
	pages={366-374},
	keywords={pricing;power markets;forecasting theory;neural nets;fuzzy logic;power system economics;learning (artificial intelligence);energy price forecasting;Ontario electricity market;power system market;artificial intelligence methods;neural networks;fuzzy logic;open access market;spot price prediction techniques;soft computing techniques;neuro-fuzzy systems;market clearing price;learning algorithms;membership functions;generator outages;Load forecasting;Economic forecasting;Power systems;Artificial intelligence;Fuzzy logic;Electricity supply industry;Power markets;Intelligent networks;Artificial neural networks;ISO},
	doi={10.1109/TPWRS.2003.821470},
	ISSN={0885-8950},
	month={Feb},
}
@ARTICLE{
	energy_magazine,
	author={N. {Amjady} and M. {Hemmati}},
	journal={IEEE Power and Energy Magazine},
	title={Energy price forecasting - problems and proposals for such predictions},
	year={2006},
	volume={4},
	number={2},
	pages={20-29},
	keywords={power markets;power system economics;pricing;energy price forecasting;electricity market;pool system bidding;market participants;price-production schedule;production costs;market clearing price;Load forecasting;Proposals;Electricity supply industry;Pricing;Economic forecasting;Electricity supply industry deregulation;Contracts;Costs;Instruments;Power industry},
	doi={10.1109/MPAE.2006.1597990},
	ISSN={1540-7977},
	month={March},
}
@article{
	hibrid_price_forecasting,
	title = "Price forecasting of day-ahead electricity markets using a hybrid forecast method",
	journal = "Energy Conversion and Management",
	volume = "52",
	number = "5",
	pages = "2165 - 2169",
	year = "2011",
	issn = "0196-8904",
	doi = "https://doi.org/10.1016/j.enconman.2010.10.047",
	url = "http://www.sciencedirect.com/science/article/pii/S0196890410005212",
	author = "M. Shafie-khah and M. Parsa Moghaddam and M.K. Sheikh-El-Eslami",
	keywords = "Price forecast, Hybrid forecast method, Wavelet transform (WT), Auto-Regressive Integrated Moving Average (ARIMA), Radial Basis Function Neural Networks (RBFN), Particle Swarm Optimization (PSO)",
	abstract = "Energy price forecasting in a competitive electricity market is crucial for the market participants in planning their operations and managing their risk, and it is also the key information in the economic optimization of the electric power industry. However, price series usually have a complex behavior due to their nonlinearity, nonstationarity, and time variancy. In this paper, a novel hybrid method to forecast day-ahead electricity price is proposed. This hybrid method is based on wavelet transform, Auto-Regressive Integrated Moving Average (ARIMA) models and Radial Basis Function Neural Networks (RBFN). The wavelet transform provides a set of better-behaved constitutive series than price series for prediction. ARIMA model is used to generate a linear forecast, and then RBFN is developed as a tool for nonlinear pattern recognition to correct the estimation error in wavelet-ARIMA forecast. Particle Swarm Optimization (PSO) is used to optimize the network structure which makes the RBFN be adapted to the specified training set, reducing computation complexity and avoiding overfitting. The proposed method is examined on the electricity market of mainland Spain and the results are compared with some of the most recent price forecast methods. The results show that the proposed hybrid method could provide a considerable improvement for the forecasting accuracy."
}
@article{
	price_forecast_competition,
	title = "Probabilistic energy forecasting: Global Energy Forecasting Competition 2014 and beyond",
	journal = "International Journal of Forecasting",
	volume = "32",
	number = "3",
	pages = "896 - 913",
	year = "2016",
	issn = "0169-2070",
	doi = "https://doi.org/10.1016/j.ijforecast.2016.02.001",
	url = "http://www.sciencedirect.com/science/article/pii/S0169207016000133",
	author = "Tao Hong and Pierre Pinson and Shu Fan and Hamidreza Zareipour and Alberto Troccoli and Rob J. Hyndman",
	keywords = "Electric load forecasting, Electricity price forecasting, Wind power forecasting, Solar power forecasting, Probabilistic forecasting, Forecasting competition",
	abstract = "The energy industry has been going through a significant modernization process over the last decade. Its infrastructure is being upgraded rapidly. The supply, demand and prices are becoming more volatile and less predictable than ever before. Even its business model is being challenged fundamentally. In this competitive and dynamic environment, many decision-making processes rely on probabilistic forecasts to quantify the uncertain future. Although most of the papers in the energy forecasting literature focus on point or single-valued forecasts, the research interest in probabilistic energy forecasting research has taken off rapidly in recent years. In this paper, we summarize the recent research progress on probabilistic energy forecasting. A major portion of the paper is devoted to introducing the Global Energy Forecasting Competition 2014 (GEFCom2014), a probabilistic energy forecasting competition with four tracks on load, price, wind and solar forecasting, which attracted 581 participants from 61 countries. We conclude the paper with 12 predictions for the next decade of energy forecasting."
}
@MISC{
	minMaxScaler,
	TITLE = "sklearn.preprocessing.MinMaxScaler",
	AUTHOR = "Scikit Learn",
	HOWPUBLISHED = "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html",
	YEAR= "2019"
}

@article{
	adadelta,
	author    = {Matthew D. Zeiler},
	title     = {{ADADELTA:} An Adaptive Learning Rate Method},
	journal   = {CoRR},
	volume    = {abs/1212.5701},
	year      = {2012},
	url       = {http://arxiv.org/abs/1212.5701},
	archivePrefix = {arXiv},
	eprint    = {1212.5701},
	timestamp = {Mon, 13 Aug 2018 16:45:57 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1212-5701},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{
	FinancialCrisis,
	title = "Bank lending during the financial crisis of 2008",
	journal = "Journal of Financial Economics",
	volume = "97",
	number = "3",
	pages = "319 - 338",
	year = "2010",
	note = "The 2007-8 financial crisis: Lessons from corporate finance",
	issn = "0304-405X",
	doi = "https://doi.org/10.1016/j.jfineco.2009.12.001",
	url = "http://www.sciencedirect.com/science/article/pii/S0304405X09002396",
	author = "Victoria Ivashina and David Scharfstein",
	abstract = "This paper shows that new loans to large borrowers fell by 47% during the peak period of the financial crisis (fourth quarter of 2008) relative to the prior quarter and by 79% relative to the peak of the credit boom (second quarter of 2007). New lending for real investment (such as working capital and capital expenditures) fell by only 14% in the last quarter of 2008, but contracted nearly as much as new lending for restructuring (LBOs, M&As, share repurchases) relative to the peak of the credit boom. After the failure of Lehman Brothers in September 2008, there was a run by short-term bank creditors, making it difficult for banks to roll over their short term debt. We find that there was a simultaneous run by borrowers who drew down their credit lines, leading to a spike in commercial and industrial loans reported on bank balance sheets. We examine whether these two stresses on bank liquidity led them to cut lending. In particular, we show that banks cut their lending less if they had better access to deposit financing and thus, they were not as reliant on short-term debt. We also show that banks that were more vulnerable to credit-line drawdowns because they co-syndicated more of their credit lines with Lehman Brothers reduced their lending to a greater extent."
}